# KI


# KÃ¼nstliche Intelligenz â€“ Vorlesung 1 (2024)

## Modul: KÃ¼nstliche Intelligenz  
**Prof. Dr. Heinrich Jasper**  
**TU Bergakademie Freiberg**  

---

## Zielsetzung des Moduls

- **Erwerb von Kenntnissen und Fertigkeiten** in:
  - Grundlagen der KÃ¼nstlichen Intelligenz (KI)
    - Begriffsbildung
    - Methoden und Techniken
    - Anwendungsgebiete
    - Historie und Stand der Technik
  - Ãœbungen zur KI
    - Spezielle Themen
    - EinfÃ¼hrung in **PROLOG** als Programmiersprache

---

## Begriffsbildung

### Definitionen KÃ¼nstlicher Intelligenz
- **Systeme, die wie Menschen denken** (Haugeland, 1985)
- **Systeme, die wie Menschen handeln** (Rich & Knight, 1991)
- **Systeme, die rational denken** (Winston, 1992)
- **Systeme, die rational handeln** (Nilsson, 1998)

> **Zusammenfassung:** KI ist eine Informatikanwendung. Sie ist dem neuronalen Netzwerk unseres Gehirns nachempfunden. KI kann einen Ausschnitt menschlicher Intelligenz nachahmen. Das Besondere ist die FÃ¤higkeit zu lernen. Das unterscheidet KIâ€Systeme von herkÃ¶mmlichen Computerprogrammen. Statt einem Programm genau zu sagen, was es tun soll, bekommt das KIâ€System eine Aufgabe gestellt, die es selbstÃ¤ndig zu lÃ¶sen hat.

### Wichtige Merkmale
- LernfÃ¤higkeit
- AufgabenbewÃ¤ltigung ohne genaue Programmierung

---

## Motivation

- **Anwendungsfelder**:
  - Sprachverstehen (Smart Devices, GPTs)
  - Autonome Systeme (Fahrzeuge, Roboter)
  - MilitÃ¤rtechnologien (Drohnen, Kampfmaschinen)
  - Virtuelle Welten (Spiele, VR)
- **Zielsetzung**:
  - Verstehen und Beeinflussung natÃ¼rlicher Intelligenz
  - Aufbau kÃ¼nstlich intelligenter Systeme
  - Kombination beider Richtungen (Intellektik)

---

## Intelligente Agenten

- BegriffseinfÃ¼hrung durch Mind-Maps (Details folgen in spÃ¤teren Veranstaltungen)

---

## Einordnung der KI

### Forschungsgebiete:
- Kognition / Bildverarbeitung / Sprachverstehen
- Wissensverarbeitung / ProblemlÃ¶sen / Analogien
- Lernen / Autonomie / Interaktion
- Genetik / Evolution

### Technologien und Systeme:
- Suchverfahren
- Funktionale, logische, objektorientierte Programmierung
- Expertensysteme
- WissensreprÃ¤sentation / Logisches SchlieÃŸen
- Machine Learning: Clustering, Klassifikation, Assoziation
- Robotik / Agentensysteme
- Neuronale Netze
- Genetische Algorithmen

---

## Historische Grundlagen

| Bereich | Wichtige PersÃ¶nlichkeiten |
| :------ | :------------------------ |
| Philosophie | Aristoteles, Hobbes, da Vinci |
| Mathematik | Boole, Turing, GÃ¶del |
| Betriebswirtschaft | Smith, von Neumann |
| Neurowissenschaften | Broca, Berger |
| Psychologie | Wundt, Craik |
| Technische Informatik | Zuse, Turing |
| Kontrolltheorie | Wiener, McCulloch |
| Linguistik | Chomsky, Skinner |

---

## Entwicklung der KI

### FrÃ¼hzeit (1943â€“1955)
- KÃ¼nstliches Neuron
- Hebbâ€™sche Lernregel
- Turing-Test
- Erste genetische Algorithmen

### Begriffsbildung (1956)
- **Dartmouth Workshop**: GrÃ¼ndung der KI als Forschungsfeld

### Enthusiasmus (1952â€“1969)
- Entwicklung von GPS (General Problem Solver)
- Programmiersprache **LISP**
- Lernende Programme (z.B. Schach, Geometriebeweiser)

### Erste ErnÃ¼chterung (1966â€“1973)
- FÃ¶rdermittelrÃ¼ckgang wegen unerfÃ¼llter Erwartungen

### Wissensbasierte Systeme (1969â€“1990)
- Expertensysteme, Regelsysteme, WissensreprÃ¤sentation

### Erfolgreiche KI-Forschung (ab 1980)
- PROLOG, neuronale Netze, autonome Systeme, Agententechnologie

### Zweiter KI-Winter (1990â€“ca. 2010)
- EnttÃ¤uschung Ã¼ber allgemeine KI-Techniken

### Heute (2020+)
- Massive Fortschritte:
  - Autonome Fahrzeuge
  - Sprach- und Bild-KI (z.B. GPT, Stable Diffusion)
  - Integration in AlltagsgerÃ¤te (Waschmaschinen, Kreditsysteme)
- GroÃŸe Herausforderungen:
  - Ethische und gesellschaftliche Fragen
  - VerstÃ¤ndnis von Intelligenz und RationalitÃ¤t

---

## Aktuelle Anwendungen

- Autonome Computer- und Fahrzeugsysteme
- Diagnosesysteme (Medizin, Technik)
- Planungs- und Optimierungssysteme
- Robotik
- Sprachverstehen und Ãœbersetzung
- Wissensverarbeitung und Ontologien
- Semantische Suchen
- Emotionale Agenten
- Bio-/Neurologische Analogien
- Theoretische Forschung zu KI-Grundlagen

---


# VL2 - Intelligente Agenten â€“ Zusammenfassung

## Allgemeines Modell

- **Definition**: Intelligente Agenten sind Systeme, die wirklich als intelligent bezeichnet werden kÃ¶nnen.
- **Grundstruktur**:
  - **Agent** interagiert mit der **Umgebung**.
  - Nutzt **Sensoren** zur Wahrnehmung und **Aktuatoren** zur AusfÃ¼hrung von Aktionen.

```
Agent <-> Umgebung
(Sensoren zur Wahrnehmung, Aktuatoren fÃ¼r Aktionen)
```

## Rationaler Agent

- **Ziel**: Auswahl von Handlungen, die die Leistungsbewertung maximieren.
- **Leistungsbewertung**: 
  - Definiert, was ein "gutes" Verhalten ist.
  - Bewertet den Erfolg eines Agenten.
- **Wichtige Aspekte**:
  - RationalitÃ¤t bedeutet nicht Allwissenheit oder Perfektion.
  - Lernen ist zentral fÃ¼r die Verbesserung der Leistung.

## Arbeitsumgebungen von Agenten (Beispiele)

| Agententyp | Leistungsbewertung | Umgebung | Aktuatoren | Sensoren |
|:---|:---|:---|:---|:---|
| Medizinisches Diagnosesystem | Gesunder Patient, minimale Kosten/Klagen | Patient, Krankenhaus, Team, Medikamente | Fragen, Untersuchungen, Diagnosen, Empfehlungen | Tastatureingaben, Symptome, Befunde |
| Satellitenbildanalyse | Korrekte Bildkategorisierung | Downlink vom Satelliten | Anzeige der Kategorisierung | Farbpixelarrays |
| Packroboter fÃ¼r Teile | Prozentsatz korrekter Teile | FlieÃŸband mit Teilen, BehÃ¤lter | Arm und Greifhand | Kamera, Winkelsensoren |
| Raffinerie-Controller | Maximale Reinheit/FÃ¶rdermenge/Sicherheit | Raffinerie, Arbeiter | Ventile, Pumpen, Heizungen, Anzeigen | Temperatur-, Druck-, chemische Sensoren |
| Interaktiver Englischlehrer | Maximale Testergebnisse | SchÃ¼ler, PrÃ¼fungskommission | Ãœbungen, VorschlÃ¤ge, Korrekturen | Tastatureingabe |

### Weitere Beispiele:
- **Drohne**: Mission auf PlanetenoberflÃ¤che, Sensor- und Waffensteuerung.
- **Autonomes Fahrzeug**: Gute Fahrt von A nach B, Kommunikation mit Umwelt und anderen Fahrzeugen.

## Kategorisierung von Arbeitsumgebungen

- **VollstÃ¤ndig vs. Teilweise beobachtbar**: Sind alle Informationen der Umgebung verfÃ¼gbar?
- **Deterministisch vs. Stochastisch**: Gibt es ZufallseinflÃ¼sse?
- **Episodisch vs. Sequenziell**: Einzelne Entscheidungen oder verkettete?
- **Statisch vs. Dynamisch**: VerÃ¤ndert sich die Umgebung unabhÃ¤ngig vom Agenten?
- **Diskret vs. Stetig**: Endliche vs. kontinuierliche ZustÃ¤nde.
- **Einzelagent vs. Multiagenten**: Arbeitet der Agent alleine oder kooperativ?

## Struktur eines Agenten

- **Architektur**: Physische Komponenten wie Sensoren, Aktuatoren.
- **Programm**: Logik und Algorithmen, die das Verhalten steuern.

## Typen von Intelligenten Agenten

1. **Einfache Reflex-Agenten**:
   - Entscheidung nur anhand aktueller Wahrnehmung.
   - Realisiert Ã¼ber Bedingungs-/Aktions-Tabellen.

2. **Modellbasierte Reflex-Agenten**:
   - FÃ¼hren ein Modell der Welt basierend auf bisherigen Wahrnehmungen.
   
3. **Zielbasierte Agenten**:
   - Planen Handlungen, um definierte Ziele zu erreichen.

4. **Nutzenbasierte Agenten**:
   - Bewerten verschiedene ZustÃ¤nde und wÃ¤hlen den besten.

5. **Lernende Agenten**:
   - Verbesserung der Leistung durch Feedback und Lernalgorithmen.

## Reflexagenten â€“ Probleme

- **Table-Driven Agent**:
  - Realisierung Ã¼ber eine Tabelle, die Wahrnehmungen Aktionen zuordnet.
  - Unpraktikabel: Bei groÃŸer Datenmenge explodiert die GrÃ¶ÃŸe der Tabelle exponentiell.

- **Beispiel**:
  - Sensor liefert 27 MB/Sekunde, 1 Stunde Fahrzeit â‡’ gigantische Tabelle (mehr als Atome im beobachtbaren Universum).

## Agenten und Wissen

- **Wissensbasiertes System**:
  - EnthÃ¤lt eine **Wissensbasis**, ein **Inferenzsystem**, ein **Wissensmodell** und nutzt eine **Modellierungssprache**.

- **Verhaltensbasiertes System**:
  - Direktes Handeln durch Regeln, ohne tiefgreifende WissensreprÃ¤sentation.

### Ãœbersicht:

| Kategorie | Beschreibung |
|:---|:---|
| KÃ¼nstlich-intelligente Systeme | Ãœberbegriff |
| Wissensbasierte Systeme | Nutzung von explizitem Wissen |
| Verhaltensbasierte Systeme | Direkte Aktion ohne tiefes Wissen |
| Expertensysteme | Spezialwissen + Schlussfolgern auf engen Aufgabengebieten |

## Expertensysteme (XPS)

- **Ziel**: Simulation des Fachwissens und der ProblemlÃ¶sungsstrategien von Experten.
- **Vorgehen**:
  - Wissen wird formalisiert und maschinell nutzbar gemacht.
  - Wissensingenieur implementiert die ProblemlÃ¶sungsstrategien.
  
- **Vorteil**:
  - Ã„nderung und Wartung einfacher als bei konventionellen Programmen durch klare Trennung von Wissen und Strategie.

## Komponenten eines Expertensystems

- **Benutzungsschnittstelle**: Interaktion mit dem Benutzer.
- **Interviewerkomponente**: Aufnahme neuer Fakten.
- **ErklÃ¤rungskomponente**: BegrÃ¼ndung von Entscheidungen.


- **Inferenzsystem**: Schlussfolgerung von neuen Erkenntnissen.
- **Wissensakquisitionskomponente**: Integration neuen Wissens.
- **Wissensbasis**: Zentrale Sammlung von Fakten und Regeln.
- **Wissensmodell** (Knowledge Representation Model): Die Art und Weise, wie Wissen im System dargestellt wird.
  - Beispiele:
  - Regeln (Wenn-Dann-Form)
  - Frames (Objekte mit Attributen)
  - Ontologien (strukturierte Begriffe und Relationen)
  - Semantische Netze oder Logikbasierte Modelle
- **Modelierungssprache**: Eine formale Sprache zur Darstellung von Wissen.
  - Beispiele:
  - Prolog
  - OWL (Web Ontology Language)
  - LISP, CLISP


# VL3 Exkurs: PROLOG â€“ Logikprogrammierung in der KÃ¼nstlichen Intelligenz

## ğŸ¯ Ziel
- Wissensverarbeitung mittels **Logikprogrammierung**
- EinfÃ¼hrung in die Programmiersprache **PROLOG** (*Programming in Logic*)

## ğŸ“š Historischer Hintergrund

| Forscher        | Beitrag                                                                 |
|----------------|--------------------------------------------------------------------------|
| Frege (~1880)  | Begriffswelt als mathematische Sprache                                   |
| Herbrand, Skolem, GÃ¶del (1920â€“1935) | Mathematischer Beweisaufbau                         |
| Robinson (1965)| Resolution (Schlussfolgerung aus Axiomen)                                |
| Colmerauer (1972)| Entwicklung von PROLOG mit Resolution & Unifikation                    |
| Kowalski (~1982)| â€Algorithm = Logic + Controlâ€œ                                           |

## ğŸ”¤ Grundelemente von PROLOG

### 1. **Fakten**
```prolog
auto.
name(bernd).
vater_von(bernd, erwin).
```

### 2. **Regeln**
```prolog
vorfahr_von(X,Y) :- vater_von(X,Y).
vorfahr_von(X,Y) :- mutter_von(X,Y).
```

### 3. **Abfragen**
```prolog
?- vater_von(bernd, X).
X = erwin.
```

## ğŸ” PROLOG-Prinzipien

### a) Fakten
```prolog
fleisch(schnitzel).
fisch(aal).
verheiratet(bernd, ilse).
```

### b) Anfragen
```prolog
?- fleisch(schnitzel).  % yes
?- fleisch(aal).        % no
?- fisch(X).            % X = aal; X = scholle
```

### c) Regeln
```prolog
gesund(X) :- obst(X).
obst(apfel).
```

### d) Suchstrategie
- Tiefensuche mit Backtracking
- Regelreihenfolge wichtig!
- Achtung: Kann zu Nicht-Terminierung fÃ¼hren.

## ğŸ§± Objekte in PROLOG

### a) Atome, Zahlen, Strukturen
```prolog
geboren(fritz, 1, 10, 1938).
geboren(fritz, datum(1,10,1938)).
```

### b) Operatoren
```prolog
1 + 3 * 4  => +(1, *(3,4))
```

### c) Listen
```prolog
[]
[1]
[x,y]
[a|[b|[c]]]
```

### d) Variablen
```prolog
Vater
_vater
_
```

### e) Terme
```prolog
?- istVatervon(zeus, ares). % yes
?- 2+3 = 5.                 % no
```

## ğŸ§  Fakten und Regeln

### 3. **Fakten**
```prolog
katze(mieze).
```

### 4. **Regeln**
```prolog
tier(X) :- katze(X), lebt(X).
```

## ğŸ” Resolutionsprinzip
- Unifikation:	Struktureller Vergleich zweier Terme
- Substitution:	Bei erfolgreicher Unifikation werden die Variablen durch konkrete Werte ersetzt. Das nennt man Substitution.
- Resolution:	Anwendung von Regeln/Fakten durch Unifikation + Substitution
- Backtracking:	RÃ¼ckverfolgung zur nÃ¤chsten Alternative bei Fehlschlag



## ğŸ” PROLOG-Prozeduren & Programme

### Definition:
- Programm = Klauseln (Fakten + Regeln)
- Prozedur = gleiche Kopf-Funktoren
- Anfrage = spezielle Klausel

## ğŸ“Š Semantik von PROLOG

- Semantik = Beweise im SLD-Resolutionsbaum \\
SLD: Selektive lineare Definite-Clause-Resolution

AuflÃ¶sung erfolgt durch sukzessives Ersetzen von Zielen durch RegelkÃ¶pfe

Backtracking, sobald keine Regel anwendbar ist

Liefert Beweise in Form eines Herleitungsbaums

## âœ… Zusammenfassung

- PROLOG: deklarative Sprache zur Wissensverarbeitung
- Prinzipien: Fakten, Regeln, Abfragen, Backtracking, Unifikation
- Anwendung: symbolische KI, Expertensysteme, Sprache



# VL4 ğŸ¤– KÃ¼nstliche Intelligenz â€“ ProblemlÃ¶sung durch Suchen

## ğŸ” ProblemlÃ¶sender Agent

- Zielbasiert: Ziel ist durch einen oder mehrere wÃ¼nschenswerte ZustÃ¤nde definiert.
- Keine Begrenzung der ZustÃ¤nde im Voraus.
- Ziel: Finde eine Aktionsfolge, die zum Ziel fÃ¼hrt und fÃ¼hre sie aus.

### Parameter zur Problemformulierung:
- Wie ist das Ziel definiert?
- Welche ZustÃ¤nde sind relevant?
- Welche Aktionen sind mÃ¶glich?

### Begriffe:
- Suche = Ermittlung der Aktionsfolge
- Agentenmodell: **Formulieren â€“ Suchen â€“ AusfÃ¼hren**
- **Uninformierte Suche**: keine Information Ã¼ber QualitÃ¤t der ZustÃ¤nde
- **Informierte Suche**: Bewertung der ZustÃ¤nde mÃ¶glich

---

## ğŸ§  Einfacher ProblemlÃ¶ser (Pseudocode)

```pseudo
function EinfacherProblemlÃ¶ser(percept) returns action
    static: seq â† []
    state â† update_state(state, percept)

    if seq is empty:
        goal â† formulate_goal(state)
        problem â† formulate_problem(state, goal)
        seq â† search(problem)

    if seq not empty:
        action â† first(seq)
        seq â† rest(seq)

    return action
end
```

---

## ğŸ“ Wohldefinierte Probleme

- **Ausgangszustand**
- **Nachfolgerfunktion**: liefert `<Aktion, Nachfolgerzustand>`
- **Zieltest**: prÃ¼ft Zielzustand
- **Pfadkosten**: Summe der Aktionskosten

**Zustandsraum** = gerichteter Graph

**Optimale LÃ¶sung** = LÃ¶sung mit minimalen Pfadkosten

---

## â™Ÿï¸ Beispielprobleme

### ğŸ§© 8-Puzzle

- ZustÃ¤nde: Positionen der Zahlen & Leerfeld
- Nachfolgerfunktion: Bewegung des Leerfelds (oben, unten, links, rechts)
- Zieltest: erreicht Zielanordnung
- Pfadkosten: 1 pro Bewegung

### ğŸ‘¸ 8-Damen-Problem

- Ziel: 8 Damen auf Schachbrett, keine bedroht eine andere
- Alternative Zustandsdarstellung reduziert Anzahl zu prÃ¼fender ZustÃ¤nde

---

## ğŸšš Praktische Probleme

- Routenplanung, Logistik, Handlungsplanung
- Schaltungsdesign
- Roboternavigation
- Internet-Suche

---

## ğŸŒ² SuchbÃ¤ume und Strategien

### Definition eines Suchbaums:

- Wurzel = Ausgangszustand
- Kinder = Nachfolger gemÃ¤ÃŸ Nachfolgerfunktion
- Strategie bestimmt Reihung der Expansion

```pseudo
function tree-search(Problem, Strategie)
    initialisiere Suchbaum mit Ausgangsknoten
    while true:
        wenn keine Kandidaten: return Fehler
        wÃ¤hle Knoten laut Strategie
        wenn Ziel erreicht: return LÃ¶sung
        sonst: erweitere Knoten
```

---

## ğŸ”„ Uninformierte Suchstrategien

### 1. Breitensuche (BFS)
- VollstÃ¤ndig, optimal
- Zeit- & SpeicherkomplexitÃ¤t: O(b^d)

| Tiefe | Knoten    | Zeit         | Speicher    |
|-------|-----------|--------------|-------------|
| 2     | 1,100     | 0,1 Sek      | 1 MB        |
| 6     | 10^7      | 19 Minuten   | 10 GB       |
| 12    | 10^13     | 35 Jahre     | 10 PB       |

---

### 2. Tiefensuche (DFS)
- Nicht vollstÃ¤ndig, nicht optimal
- Geringer Speicherbedarf

### 3. Iterative Deepening
- Kombiniert BFS & DFS

### 4. Bidirektionale Suche
- Zwei gleichzeitige Suchen von Start und Ziel
- KomplexitÃ¤t: O(b^(d/2))

### 5. Weitere Strategien
- Uniforme-Kosten-Suche
- Begrenzte-Tiefen-Suche
- Iterative-Tiefen-Suche

---

## ğŸ§  Informierte Suchstrategien

- Nutzung von Heuristiken h(n)

### Greedy Best-First Search
- WÃ¤hlt immer den Knoten mit dem kleinsten geschÃ¤tzten Abstand zum Ziel. h(n)
- Risiko: Sackgassen
- Schnell, aber nicht optimal, da es AbkÃ¼rzungen Ã¼bersehen kann.

### A*-Suche
- f(n) = g(n) + h(n)
- g(n): Kosten bisher
- h(n): geschÃ¤tzte Kosten zum Ziel
- Kombination aus optimal & effizient
- Suche mit Blick auf Vergangenheit und Zukunft.

---

## ğŸ§— Lokale Suche & Optimierung

### Hillclimbing
- Folge dem besten lokalen Nachfolger mit dem besten Heuristikwert.
- Gefahr: lokales Optimum

### Simulated Annealing
- Erlaubt gelegentlich auch schlechtere LÃ¶sungen
- Nutzt Temperaturparameter T und Wahrscheinlichkeit zur Akzeptanz

---

## ğŸ§¬ EvolutionÃ¤re Algorithmen (EA)

- Simulation biologischer Evolution
- Individuen = LÃ¶sungskandidaten
- Fitnessfunktion = Bewertung

### Hauptkomponenten:
- **Rekombination r**: Kombination zweier Individuen
- **Mutation m**: zufÃ¤llige VerÃ¤nderung
- **Selektion s**: Auswahl fitter Individuen
- **Abbruchbedingung z**

### Ablaufschema:
```text
Initialisierung: P(0)
Bewertung: f(a_i)
while !Abbruch:
    Rekombination
    Mutation
    Bewertung
    Selektion
    t = t + 1
```

---

## ğŸ§ª Evolutionsstrategien (ES)

- Ein anderer Typ von evolutionÃ¤rem Algorithmus, entwickelt in Deutschland (Rechenberg, Schwefel).
- ğŸ§  Besonderheiten:
  - Fokus auf reale Zahlen (nicht Bitstrings!)
  - StÃ¤rker betont: Mutation statt Crossover
  - Anpassung der MutationsstÃ¤rke Ã¼ber Zeit (selbstadaptiv)
- Besonders gut fÃ¼r kontinuierliche Optimierungsprobleme (z.â€¯B. Maschinensteuerung, Robotik)

### Beispiel:
- F(x1,x2) = x1Â² + x2Â²
- Individuum = (x1, x2, s1, s2)
- Mutation und Rekombination Ã¼ber Strategieparameter

---

## ğŸ§¬ Genetische Algorithmen (GA)

- Bitstring-ReprÃ¤sentation der Individuen als Genotyp
- Operatoren: **Crossover**, **Mutation**, **Selektion**
- KÃ¶nnen auch in Problemen ohne exakte mathematische Beschreibung eingesetzt werden
- Suche im diskreten Raum
- Nutzen: Scheduling (z.â€¯B. FlugplÃ¤ne)
### Crossover:
- Zwei Eltern â†’ Kind durch Bittausch an zufÃ¤lliger Stelle

### Mutation:
- Flip einzelner Bits mit geringer Wahrscheinlichkeit

---

## ğŸ“Œ Fazit

- Suche ist zentrales Konzept in der KI
- Informierte Strategien und heuristische Verfahren bieten Effizienzvorteile
- Lokale und evolutionÃ¤re Verfahren ergÃ¤nzen die klassischen Suchalgorithmen bei komplexen Problemen


# VL5 ğŸ“š KÃ¼nstliche Intelligenz â€“ WissensreprÃ¤sentation & Logik

## ğŸ¤– Logisch schlieÃŸender Agent

ein Agent, der Wissen Ã¼ber die reale Welt enthÃ¤lt, das
- aus der Beschreibung mÃ¶glicher ZustÃ¤nde, Operationen und ZusammenhÃ¤nge besteht,
- zur Ableitung von Zustandseigenschaften und Operationsfolgen genutzt werden kann,
- verÃ¤ndert bzw. gelernt werden kann.

### Komponenten:
- **Wissensbasis**: Menge von SÃ¤tzen Ã¼ber die reale Welt
- **Inferenzverfahren**: Ableitung neuer SÃ¤tze
- **WissensreprÃ¤sentationssprache**:
  - **Syntax**: ReprÃ¤sentationen im Agenten
  - **Semantik**: Fakten der realen Welt


- Beweis: Aufzeichnung der Anwendung von Schlussregeln eines Inferenzverfahrens
- Theorie: Menge der aus einem KalkÃ¼l ableitbaren Formeln
---
## Aussagelogik
Behandelt aussagenlogische Variablen, die entweder wahr oder falsch sind.
Man arbeitet mit einfachen Aussagen und VerknÃ¼pfungen wie UND, ODER, NICHT, â†’ (Implikation)

### Hilbert-Axiomensystemen (Aussagelogik):
Das Hilbert-System (benannt nach David Hilbert) ist ein axiomatisches System, das mit:

- einer kleinen Anzahl von Axiomen (Grundformeln), und
  - De Morgen, Verschmelzung, Konjunktion, ...
- wenigen Schlussregeln (v.â€¯a. Modus Ponens)

jede gÃ¼ltige Aussage der Aussagenlogik beweisbar machen will.

Eigenschaften: vollstÃ¤ndig, **entscheidbar**, wiederspruchsfrei, monoton, unabhÃ¤ngig

## PrÃ¤dikatenlogik
- Erweitert die Aussagenlogik um Objekte, Eigenschaften und Quantoren.
- Hier kann man Ã¼ber Dinge in der Welt sprechen â€“ nicht nur Ã¼ber Wahrheitswerte.

- Eigenschaften: vollstÃ¤ndig, **nicht entscheidbar**, wiederspruchsfrei, monoton, unabhÃ¤ngig
  - nicht entscheidbar: Es gibt kein Verfahren, das fÃ¼r alle Aussagen entscheidet, ob sie gÃ¼ltig sind (wegen der Unendlichkeit von DomÃ¤nen)


Beide Logiksysteme sind vollstÃ¤ndig, widerspruchsfrei, monoton und unabhÃ¤ngig.
Aber nur die Aussagenlogik ist entscheidbar â€“ die PrÃ¤dikatenlogik nicht.
# VL 6
- Eine **Klausel** ist eine ODER-VerknÃ¼pfung (Disjunktion) von Literalen.
  - vollstÃ¤ndig, nicht entscheidbar
- Eine **Hornklausel** ist eine spezielle Klausel mit hÃ¶chstens einem positiven Literal.
- Hornklauseln sind Grundlage von Prolog und ermÃ¶glichen effizientes logisches SchlieÃŸen.
  - Sie ermÃ¶glichen einfache Implementierung logischer Systeme wie Expertensysteme oder Regelwerke
  - nicht vollstÃ¤ndig, nicht entscheidbar

## Ableitungsstrategien
### VorwÃ¤rtsverkettung:
- Startet mit Fakten, leitet neue ab, bis das Ziel erreicht ist.
- KonfliktlÃ¶sung: PrioritÃ¤ten, Reihenfolge, SpezifitÃ¤t.
  - Wenn mehrere Regeln gleichzeitig anwendbar sind, spricht man von einem Konflikt. Eine KonfliktlÃ¶sungsstrategie entscheidet, welche Regel zuerst ausgefÃ¼hrt wird.
### RÃ¼ckwÃ¤rtsverkettung:
- Man beginnt mit einer Anfrage oder Hypothese und sucht rÃ¼ckwÃ¤rts, ob es Regeln und Fakten gibt, mit denen man das Ziel beweisen kann.
- Vergleich: Ã„hnlich zu Prologs Tiefensuche.

## Regelbasiertes System
Ein regelbasiertes System (auch Produktionssystem genannt) ist ein wissensbasiertes System, das automatisch Schlussfolgerungen zieht und Entscheidungen trifft, indem es Regeln auf bekannte Fakten anwendet.

Ein regelbasiertes System besteht aus
- Datenbasis mit den gÃ¼ltigen Fakten
- Regeln zur Herleitung neuer Fakten / AusfÃ¼hrung von Aktionen
- Regelinterpreter zur Steuerung des Herleitungs-/AusfÃ¼hrungsprozesses

Prinzipielle Abarbeitungsmechanismen eines Regelinterpreters
- VorwÃ¤rtsverkettung: feuere Regeln solange, bis sich die Datenbasis (eine Menge von Fakten) nicht mehr Ã¤ndert
oder Abbruchbedingung erfÃ¼llt ist
- RÃ¼ckwÃ¤rtsverkettung: Vom Ziel ausgehend, werden Vorbedingungen etabliert; prÃ¼fe, ob Vorbedingungen
erfÃ¼llbar (Fakten oder RÃ¼ckfragen beim Nutzer), ansonsten: Vorbedingungen sind das nÃ¤chste Ziel.


Was ist eine spezifischere Regel?
- Eine spezifischere Regel hat mehr Bedingungen auf der linken Seite (PrÃ¤misse) â†’ sie ist eingeschrÃ¤nkter, wird also selten angewendet, aber liefert gezieltere SchlÃ¼sse.


## Frames
Idee: Aussagen Ã¼ber ein Objekt strukturiert zusammenfassen
- Ein Frame ist eine Art Datenstruktur, die ein Konzept, Objekt oder eine Situation beschreibt â€“ Ã¤hnlich einem Objekt in der Objektorientierten Programmierung.

- Ein Frame besteht aus:
  - Slots (Attribute, Eigenschaften, Fragen)
  - Slot-Filler (Werte, Regeln, andere Frames)

- Sie sind vererbbar und kÃ¶nnen Prozeduren enthalten (Programme, die Eigenschaften eines Objekts zugeordnet sind)

- Frames eignen sich besonders gut zur reprÃ¤sentativen Darstellung realer Objekte und sind leicht erweiterbar.
- FRL (Frame Representation Language) ist eine spezielle ReprÃ¤sentationssprache, die entwickelt wurde, um Frames formal darzustellen und zu verarbeiten

### Kognitive Wurzel:
Der Begriff â€kognitive Wurzelâ€œ weist darauf hin, dass Frames auf Beobachtungen der menschlichen Kognition beruhen â€“ also wie Menschen Wissen speichern, organisieren und abrufen.

## Semantische Netze
Ein semantisches Netz ist eine graphbasierte Wissensdarstellung, bei der Konzepte (Knoten) und deren Beziehungen (Kanten) visuell und logisch dargestellt werden.

- Eigenschaften:
  - Knoten = Begriffe/Objekte (z.â€¯B. â€Hundâ€œ, â€Tierâ€œ)
  - Kanten = Beziehungen (z.â€¯B. â€ist-einâ€œ, â€hat-Teilâ€œ, â€lebt-inâ€œ)
  - Beziehungen sind oft gerichtet: von Subjekt zu Objekt

- Nutzen:
  - Intuitive Visualisierung von Wissen
  - Wird oft fÃ¼r Sprachverarbeitung und Ontologien genutzt

Ein semantisches Netz stellt Wissen in Form eines gerichteten Graphen dar â€“ mit Knoten als Objekten und Kanten als Relationen. Es eignet sich gut zur Vererbung und Konzeptdarstellung.

### KL-ONE
KL-ONE ist eine formale Weiterentwicklung semantischer Netze.
Es ist ein strenges, logikbasiertes Klassifikationssystem, das Begriffshierarchien definiert â€“ also ein Begriffsnetz mit Logikregeln.

- Grundlage fÃ¼r viele moderne Ontologie-Systeme wie OWL


## Constrains Netze
Ein Constraint-Netz ist eine graphische Darstellung eines Constraint-Satisfaction-Problems (CSP).
Es zeigt, welche Variablen vorkommen, welche Wertebereiche (DomÃ¤nen) sie haben, und welche EinschrÃ¤nkungen (Constraints) zwischen ihnen bestehen.

Nutze:
  - StundenplÃ¤ne
  - Sudoku
  - Routenplanung

# VL 7
## Was ist ein Plan-Agent?
![alt text](image.png)

Merkmale:
- Hat ein Modell der Welt (ZustÃ¤nde, Aktionen, Effekte)
- Nutzt logische ReprÃ¤sentation (z.â€¯B. SituationskalkÃ¼l)
- Wendet Planungsalgorithmen an

## SituationskalkÃ¼l
Zur formalen Beschreibung von Handlungen und deren Effekten
![alt text](image-2.png)
ğŸ˜° Herausforderung: Frame-Problem
â†’ Wie stellt man formell dar, was sich nicht Ã¤ndert, wenn eine Aktion ausgefÃ¼hrt wird?

Beispiel: Wenn man die TÃ¼r Ã¶ffnet, bleiben Tisch, Stuhl, Fensterzustand etc. gleich â€“ das muss extra berÃ¼cksichtigt werden.


## Was ist ein Planungsalgorithmus?
Ein Planungsalgorithmus ist ein Verfahren, das eine Reihenfolge von Aktionen erstellt, um einen Zielzustand von einem Startzustand aus zu erreichen. Typische Planalgorithen: A*-Planung, STRIPS

- Gegeben: Start-, Zielzustand, Operationen
- Erzeugen eines Intialen Planes
- Suche im Zustandsraum â†’ finde Pfad von Start â†’ Ziel
- Erzeuge Aktionsfolge (Plan)
- ÃœberprÃ¼fe wÃ¤hrend AusfÃ¼hrung: Ist der aktuelle Zustand wie erwartet?
- Bei Abweichung: Replanung

## Initialer Plan
Ein initialer Plan ist der erste Vorschlag oder Ablauf von Aktionen, der erstellt wird, um ein bestimmtes Ziel zu erreichen.

Ein Agent kann erkennen, dass der initiale Plan nicht mehr gÃ¼ltig ist, wenn:
| Methode                               | Beschreibung                                                                                         |
| ------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| **PlanÃ¼berprÃ¼fung (Plan Monitoring)** | WÃ¤hrend der AusfÃ¼hrung prÃ¼ft der Agent regelmÃ¤ÃŸig, ob alles wie geplant lÃ¤uft.                       |
| **Soll-Ist-Vergleich**                | Der Agent vergleicht erwartete ZustÃ¤nde mit aktuellen ZustÃ¤nden.                                     |
| **Fehlschlag beim AusfÃ¼hren**         | Wenn eine Aktion nicht mÃ¶glich ist (z.â€¯B. TÃ¼r ist blockiert), erkennt der Agent: Plan ist gebrochen. |
| **Sensorfeedback**                    | Neue Informationen machen den Plan veraltet oder falsch.                                             |

In solchen FÃ¤llen wird ein neuer Plan erzeugt = Replanung

# VL 8
## Lernender Agent
Ein Agent, der seine Eingaben nicht nur zur Steuerung seiner unmittelbaren Ausgaben verwendet sondern auch zur VerÃ¤nderung (Verbesserung) seiner zukÃ¼nftigen Verhaltensweise.

- Formen des Lernens:
  - Speichern von Erfahrungen, Klassifizierung, Verallgemeinerung, Theoriebildung.
  - Beispiele: Navigation, Schach, Sprachverarbeitung.

- Komponenten:
  - ProblemlÃ¶ser: Steuert das aktuelle Verhalten.
  - Lernkomponente: Passt Wissen anhand von RÃ¼ckmeldungen an.
  - Kritiker: Bewertet Erfolg/Misserfolg.
  - Problemgenerator: Erzeugt Trainingsdaten oder TestfÃ¤lle.

- Lernarten:
  - Ãœberwacht (gelabelte Daten), VerstÃ¤rkend (Belohnung/Strafe), UnÃ¼berwacht (Clustering).

### Aufgabenstellungen und Algorithmen
- **Vorhersage** (Regressionsaufgaben):
    Ziel: Funktion f(x)f(x) approximieren (z. B. mittels linearer Regression).
    - Lernkurve: Anzahl korrekt bearbeiteter Testbeispiele bei gegebener Anzahl von
Trainingsbeispielen
    - Fehlerfunktion e(h) = P(h(x) â‰  f(x)) ist zu minimieren
- **Klassifikation**: beobachtete Situation (Sensordaten) einer gegebenen Klasse zuordnen.
  - Arten von Classifiern
    - EntscheidungsbÃ¤ume
    - RegessionsbÃ¤ume etc. (a.a.O.)
    - Semantische Netze etc. (a.a.O.)
    - Multidimensionale Zuordnungen

  - **EntscheidunsbÃ¤ume**: Ein Entscheidungsbaum ist ein baumartiges Klassifikationsmodell, das rekursiv Attribute auswÃ¤hlt, um Daten in Klassen zu unterteilen. Die Attributauswahl basiert z.â€¯B. auf Informationsgewinn (Entropie).

    - ğŸ¯Vorteile von EntscheidungsbÃ¤umen
      - Einfach zu verstehen und interpretieren
      - KÃ¶nnen symbolisches Wissen erzeugen
      - Arbeiten gut mit kategorischen und numerischen Daten
      - Keine Annahme Ã¼ber Datenverteilung nÃ¶tig

    - âš ï¸ Nachteile
      - Overfitting, wenn Baum zu tief ist
      - Instabil gegenÃ¼ber kleinen Ã„nderungen in den Daten
      - Pruning (Beschneiden) notwendig, um Generalisierung zu verbessern


  - **kNN (k-Nearest Neighbors)**: kNN ist ein klassifikationsbasiertes Lernverfahren, das eine neue Eingabe auf Basis der k nÃ¤chsten Trainingsbeispiele klassifiziert. Es ist einfach, nicht-parametrisch, aber rechenintensiv beim Vorhersagen.

  Wie funktioniert kNN?
  - Du hast eine Menge gelabelter Datenpunkte (Trainingsdaten).
  - FÃ¼r einen neuen, unbekannten Punkt:
    - Berechne den Abstand zu allen Trainingspunkten (z.â€¯B. euklidisch).
    - WÃ¤hle die k nÃ¤chstgelegenen Nachbarn.
    - Mehrheitsabstimmung (Voting): Die Klasse, die am hÃ¤ufigsten unter den k Nachbarn vorkommt, wird zugewiesen.

### Clustering:
Clustering ist ein Verfahren des unÃ¼berwachten Lernens, bei dem Datenobjekte in Gruppen (Cluster) eingeteilt werden, sodass:

- Objekte innerhalb eines Clusters mÃ¶glichst Ã¤hnlich sind
- Objekte zwischen Clustern mÃ¶glichst unterschiedlich

âœ… Keine Klassenlabels notwendig! \\
Bsp.: Kunden in Gruppen mit Ã¤hnlichem Kaufverhalten einteilen

#### Wie funktioniert k-Means?
k-Means ist ein iteratives Clustering-Verfahren, das Daten in k Cluster unterteilt. \\
Ziel: Minimierung der Summe der AbstÃ¤nde zwischen Datenpunkten und ihrem jeweiligen Cluster-Zentrum (Centroid)

ğŸ” Ablauf des k-Means-Algorithmus:
- WÃ¤hle k: Anzahl der Cluster
- Initialisiere k Zentren zufÃ¤llig
- Zuordnungsschritt (Assignment):
- Weise jeden Punkt dem nÃ¤chsten Zentrum zu (z.â€¯B. nach euklidischer Distanz)
- Update-Schritt:
- Berechne fÃ¼r jeden Cluster das neue Zentrum (Mittelwert der zugewiesenen Punkte)
- Wiederhole 3 & 4, bis sich die Zentren nicht mehr Ã¤ndern (Konvergenz)

### Lernen logischer Formeln
Ziel: Generierung logischer Hypothesen, die Trainingsdaten konsistent abbilden.
### Lernen besseren Verhaltens
- KÃ¼nstliche Neuronale Netze (KNN/ANN):
    - Prinzip: Anpassung von Gewichten durch Backpropagation (FehlerrÃ¼ckfÃ¼hrung).
    - Deep Learning: Mehrschichtige Netze fÃ¼r komplexe Mustererkennung (z. B. Bilderkennung).
- VerstÃ¤rkendes Lernen:
    - Ziel: Maximierung einer Belohnungsfunktion durch Exploration/Exploitation.
    - Beispiel: Robotersteuerung, Spielstrategien (AlphaGo).

# VL 9
## âœ… Was ist ein kÃ¼nstliches Neuron?

Ein **Neuron** ist die kleinste Recheneinheit in einem neuronalen Netz.  
Es empfÃ¤ngt Eingaben, multipliziert sie mit Gewichten, addiert einen Bias und gibt das Ergebnis Ã¼ber eine **Aktivierungsfunktion** weiter.

### ğŸ”§ Aufbau eines Neurons:

![alt text](image-4.png)

- Eingaben: `xâ‚, xâ‚‚, ..., xâ‚™`
- Gewichte: `wâ‚, wâ‚‚, ..., wâ‚™`
- Bias: `b` (Verschiebung der Aktivierung)
- Suchfunktion: `z = âˆ‘(wáµ¢ * xáµ¢) + b` Die Suchfunktion ist die gewichtete Summenbildung der Eingabewerte.
Sie bestimmt, wie stark ein Neuron aktiviert wird, bevor die Aktivierungsfunktion angewendet wird.
- Aktivierungsfunktion: `a = f(z)` Die Aktivierungsfunktion nimmt den Ausgabewert der Suchfunktion und entscheidet, wie stark das Neuron feuert (also welchen Wert es weitergibt).

### ğŸ›ï¸ Typische Aktivierungsfunktionen:

| Funktion   | Formel                         | Beschreibung                        |
|------------|--------------------------------|-------------------------------------|
| Sigmoid    | `1 / (1 + e^(-z))`             | Werte zwischen 0 und 1              |
| Tanh       | `(e^z - e^-z) / (e^z + e^-z)`  | Werte zwischen -1 und 1             |
| ReLU       | `max(0, z)`                    | Beliebt, effizient, sparsam         |

---

## ğŸ¤– Neuron vs. Perzeptron

| Merkmal                 | Neuron (modern)                        | Perzeptron (klassisch)              |
|-------------------------|----------------------------------------|-------------------------------------|
| Aktivierungsfunktion    | ReLU, Sigmoid, Tanh (differenzierbar) | Schwellenwertfunktion (0/1-Ausgabe)        |
| Differenzierbar         | âœ… Ja                                  | âŒ Nein                              |
| FÃ¼r Backpropagation     | âœ… Ja                                  | âŒ Nein                              |
| Komplexe Aufgaben       | âœ… Mehrschichtnetze mÃ¶glich            | âŒ Nur lineare Trennung              |

**Merksatz:**  
> Das Perzeptron ist die Urform des Neurons mit harter Schwelle.  
> Ein modernes Neuron nutzt differenzierbare Aktivierungsfunktionen und ist trainierbar.

---

## ğŸ§± Woraus besteht eine Schicht?

Eine **Schicht (Layer)** ist eine **Gruppe von Neuronen**, die gleichzeitig arbeiten und ihre Ausgaben an die nÃ¤chste Schicht weitergeben.

### ğŸ§© Typen von Schichten:

1. **Eingabeschicht (Input Layer)**  
   â†’ Nimmt Rohdaten auf

2. **Verborgene Schicht(en) (Hidden Layer)**  
   â†’ Berechnungsschritte mit Aktivierungen

3. **Ausgabeschicht (Output Layer)**  
   â†’ Liefert Klassifikation oder Regressionswert

Ein neuronales Netz besteht aus einer Eingabeschicht (Puffer), einer oder mehreren verborgenen Schichten (Assoziierung) und einer Ausgabeschicht (Antwort).
Die Assoziierungsschicht verarbeitet die Daten und â€lerntâ€œ die Merkmale zur Klassifikation oder Entscheidung.

## ğŸ§  Klausur-MerksÃ¤tze:

- Ein **Neuron** = gewichtete Summe + Bias â†’ Aktivierungsfunktion
- Das **Perzeptron** ist eine Vorform mit Schwellwertfunktion
- Eine **Schicht** besteht aus mehreren Neuronen â€“ das Netz aus mehreren Schichten


## Was ist Backpropagation?
Backpropagation (RÃ¼ckwÃ¤rtsausbreitung) ist ein Trainingsverfahren fÃ¼r neuronale Netze, bei dem die Gewichte so angepasst werden, dass der Fehler (Loss) zwischen dem vorhergesagten und dem tatsÃ¤chlichen Wert minimiert wird.

Neuronale Netze bestehen aus vielen Schichten â€“ der Fehler der Vorhersage (z.â€¯B. falsche Klasse) muss rÃ¼ckwÃ¤rts durch das Netz propagiert werden, damit jede Gewichtung entsprechend angepasst werden kann.


Anforderungen fÃ¼r Backpropagation:
- Aktivierungsfunktionen mÃ¼ssen differenzierbar sein (z.â€¯B. Sigmoid, ReLU)
- Der Fehler muss mit einer Kostenfunktion (Loss Function) messbar sein
- StÃ¼tzverfahren: Kettenregel der Differentialrechnung

1. VorwÃ¤rtsdurchlauf (Forward Pass):
- Eingabedaten durchlaufen das Netz
- Ausgabe wird berechnet
- Fehler wird durch Vergleich mit dem Zielwert (z.â€¯B. Ã¼ber MSE oder Cross-Entropy) bestimmt
2. Fehlerberechnung:
- Differenz zwischen Ausgabe und gewÃ¼nschtem Zielwert = Loss
3. RÃ¼ckwÃ¤rtsdurchlauf (Backward Pass):
- Der Fehler wird von der Ausgabeschicht zurÃ¼ck zu den Eingabeschichten propagiert
- FÃ¼r jedes Gewicht wird der Gradient (Ableitung) des Fehlers berechnet
4. Gewichtsanpassung (Gradient Descent):
- Gewichte werden aktualisiert:

## ğŸ¤– KÃ¼nstliche Neuronale Netze â€“ Kurzfragen

### â“ Wie groÃŸ soll ein KNN sein?
> So groÃŸ wie nÃ¶tig, aber so klein wie mÃ¶glich.  
> Zu viele Neuronen â†’ Overfitting  
> Zu wenige â†’ unzureichende LernfÃ¤higkeit

---

### â“ Wie viele verborgene Schichten benÃ¶tigt man?
> FÃ¼r einfache Probleme reicht **eine** Schicht.  
> Komplexere Probleme â†’ **mehrere Schichten (Deep Learning)**  
> Achtung: Mehr Schichten = schwieriger zu trainieren

---

### â“ Kann ein trainiertes Netzwerk auf beliebige Testdaten generalisieren?
> âŒ Nein.  
> Nur wenn Testdaten **Ã¤hnlich verteilt** sind wie die Trainingsdaten.  
> Sonst drohen **Overfitting** oder schlechte Vorhersageleistung.

---

### â“ Kann man die Funktion \( y = F(X, W) \) eines trainierten Netzes finden?
> âœ… Ja, **theoretisch mÃ¶glich**, durch vollstÃ¤ndiges Einsetzen aller Gewichte und Aktivierungen.  
> âŒ Aber **praktisch unÃ¼bersichtlich** und nicht interpretierbar bei groÃŸen Netzen (nicht transparent).

# ğŸ¤– Deep Learning â€“ RNN, LSTM, CNN & Convolution

## ğŸ” Was ist ein RNN (Recurrent Neural Network)?

Ein **RNN** ist ein neuronales Netz, das fÃ¼r **sequenzielle Daten** (z.â€¯B. Sprache, Text, Zeitreihen) entwickelt wurde.  
Es nutzt eine **RÃ¼ckkopplungsschleife**, sodass **Informationen aus frÃ¼heren Zeitschritten** weitergegeben werden kÃ¶nnen.

### ğŸ”§ Besonderheiten:
- Jeder Zeitschritt erhÃ¤lt zusÃ¤tzlich zum Input auch den **Zustand vom vorherigen Schritt**:  
  \( h_t = f(Wx_t + Uh_{t-1} + b) \)
- Ideal fÃ¼r: **Texte, Sprache, Musik, Zeitreihen**

### âŒ Problem:
- **Vanishing/Exploding Gradients** â†’ Schwierigkeiten beim Lernen **langer AbhÃ¤ngigkeiten**

---

## ğŸ§  Was ist Deep Learning?

**Deep Learning** ist maschinelles Lernen mit **mehrschichtigen neuronalen Netzen** (deep = tief).

### ğŸ”§ Merkmale:
- Besteht aus **vielen Hidden Layers**
- Nutzt **Backpropagation** zur Gewichtsanpassung
- FÃ¼hrt oft zu **automatischer Merkmalsextraktion**
- Erfolgreich bei:  
  - Bildverarbeitung  
  - Sprachverarbeitung  
  - Textklassifikation  
  - Spiel-KI

---

## â³ Was ist ein LSTM (Long Short-Term Memory)?

Ein **LSTM** ist eine **erweiterte RNN-Architektur**, die das Problem des **Vanishing Gradients** lÃ¶st.

### ğŸ”§ Besonderheiten:
- Besteht aus **Speicherzellen**, die Informationen **Ã¼ber viele Zeitschritte speichern** kÃ¶nnen
- Verwendet **drei Tore**:
  - **Input Gate** â€“ entscheidet, was aufgenommen wird
  - **Forget Gate** â€“ entscheidet, was vergessen wird
  - **Output Gate** â€“ entscheidet, was ausgegeben wird

âœ… LSTM kann **langfristige AbhÃ¤ngigkeiten** lernen  
z.â€¯B. beim **Ãœbersetzen ganzer SÃ¤tze**

---

## ğŸ–¼ï¸ Was ist ein CNN (Convolutional Neural Network)?

Ein **CNN** ist ein neuronales Netz, das speziell fÃ¼r **Bild- und Mustererkennung** entwickelt wurde.

### ğŸ” Eigenschaften:
- Erkennt **lokale Muster** (z.â€¯B. Kanten, Farben) mithilfe von **Convolution-Filtern**
- Nutzt **Pooling-Schichten** zur Reduktion der Datenmenge
- Besteht typischerweise aus:
  - **Convolutional Layer**
  - **Activation Layer** (z.â€¯B. ReLU)
  - **Pooling Layer**
  - **Dense (fully connected) Layer**

---

## ğŸ” Was ist eine Convolution (Faltung)?

> Eine **Convolution** ist eine mathematische Operation, bei der ein **kleiner Filter (Kernel)** Ã¼ber das Eingabebild **gleitet** (Sliding Window).  
> Der Filter erkennt dabei **lokale Merkmale** wie Ecken oder Kanten.

### Beispiel:
Ein 3Ã—3-Filter gleitet Ã¼ber ein Bild, multipliziert mit lokalen Pixelwerten und erzeugt so eine **Feature Map**.

âœ… Vorteil:
- Weniger Parameter
- Gute Generalisierung
- Lokale Erkennung bei gleichzeitiger Effizienz

---
# <span style="color:red"> Bis hier!</span>
## ğŸ§© Was ist Pooling (in CNNs)?

**Pooling** ist eine Methode zur **Verkleinerung** der Feature Maps in **Convolutional Neural Networks (CNNs)**.  
Ziel: **wichtigste Informationen behalten**, aber **GrÃ¶ÃŸe und KomplexitÃ¤t reduzieren**.

### ğŸ“‰ Vorteile:
- Spart Rechenleistung
- Verhindert Overfitting
- Sorgt fÃ¼r **Translationstoleranz**

---

## ğŸ” Was ist Max Pooling?

Beim **Max Pooling** wird aus jedem Pooling-Fenster (z.â€¯B. 2Ã—2) der **grÃ¶ÃŸte Wert** ausgewÃ¤hlt.


## ğŸ“˜ Klausur-MerksÃ¤tze:

| Begriff | ErklÃ¤rung |
|--------|-----------|
| **RNN** | Neuronales Netz mit GedÃ¤chtnis fÃ¼r Sequenzen. Speichert vorherige ZustÃ¤nde Ã¼ber RÃ¼ckkopplung. |
| **Deep Learning** | Verwendung tiefer neuronaler Netze mit mehreren Hidden Layers zur Mustererkennung. |
| **LSTM** | Erweiterung von RNN mit â€GedÃ¤chtnisâ€œ (Zellen + Gates) zur Ãœberwindung des Vanishing Gradient. |
| **CNN** | Netz fÃ¼r Bilderkennung, das Ã¼ber Convolution lokale Muster erkennt und verarbeitet. |
| **Convolution** | Mathematischer Filtervorgang, bei dem Merkmale lokal aus Bildern extrahiert werden. |
| **Pooling** reduziert die GrÃ¶ÃŸe der Feature Maps und hebt wichtige Informationen hervor.|
| **Max Pooling** wÃ¤hlt pro Bereich den grÃ¶ÃŸten Wert â€“ Fokus auf starke Merkmale.|


## ğŸ“š Was ist ein LLM (Large Language Model)?

Ein **LLM** ist ein groÃŸes Sprachmodell, das mit **riesigen Mengen an Textdaten** trainiert wurde, um **Sprache zu verstehen und zu erzeugen**.

### ğŸ”§ Merkmale:
- Basiert meist auf der **Transformer-Architektur**
- Besteht aus **Hunderten Millionen bis Milliarden von Parametern**
- Beherrscht viele Aufgaben:
  - Textgenerierung
  - Zusammenfassung
  - Ãœbersetzung
  - Fragebeantwortung
  - CodevervollstÃ¤ndigung

### ğŸ§  Beispiele:
- GPT (OpenAI)
- BERT (Google)
- LLaMA (Meta)
- Claude (Anthropic)

## ğŸ“˜ Klausur-MerksÃ¤tze:

- **LLMs** sind riesige Sprachmodelle, die auf Basis von Transformern trainiert wurden.


# VL 11 und 12
![alt text](image-3.png)

- Bsp.: Medizin, Technik

### unbedingte Wahrscheinlichkeit: a priori
Die unbedingte Wahrscheinlichkeit ist die â€einfacheâ€œ Wahrscheinlichkeit eines Ereignisses â€“ ohne dass irgendwelche weiteren Informationen bekannt sind.Â´

### bedingte Wahrscheinlichkeit: a posteriori
Die bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit eines Ereignisses unter der Bedingung, dass ein anderes Ereignis bereits eingetreten ist.

**Der ZUsammenhang beider wird bei der Bayesschen Regel benutzt**

## Was ist ein kausales Netzwerk?
Ein kausales Netzwerk ist ein gerichteter Graph, der kausale ZusammenhÃ¤nge zwischen Variablen modelliert.

Man kann es sich als ein Bayessches Netz vorstellen, bei dem die Kanten kausale Beziehungen und nicht nur statistische AbhÃ¤ngigkeiten ausdrÃ¼cken.

### Unterschied zu einem normalen (Bayesschen) Netzwerk
Ein Bayessches Netz beschreibt bedingte Wahrscheinlichkeiten und statistische AbhÃ¤ngigkeiten.
Ein kausales Netz geht weiter und beschreibt auch, was passiert, wenn man eingreift (interveniert).

## ğŸ” 1. Grundlagen des probabilistischen SchlieÃŸens

- **Ziel**: Bewertung von Aussagen mit Wahrscheinlichkeiten, um Unsicherheiten abzubilden.
- **Herkunft der Unsicherheiten**:
  - ReprÃ¤sentative Statistiken
  - ExperteneinschÃ¤tzungen

### Anwendungsbereich:
- **Diagnostik**:
  - Symptome â†’ mÃ¶gliche Diagnosen
  - Unsicherheiten durch:
    - Symptomerhebung
    - Symptombewertung
    - UnzulÃ¤nglichkeiten des Verrechnungsschemas

### Kategorien von Unsicherheit (vereinfachte Einteilung):
- sicher
- wahrscheinlich
- mÃ¶glich

### Verrechnungsschemata:
- Einfache, oft ad-hoc ReprÃ¤sentationen
- Kritik: Mangelnde theoretische Fundierung

## ğŸ§  2. Diagnostik als Klassifikationsproblem

- Zwei disjunkte Mengen:
  - **S** = Symptome
  - **D** = Diagnosen
- Gegeben: Teilmenge der Symptome
- Gesucht: Wahrscheinlichste Diagnose(n)
- MÃ¶glichkeit, gezielt **weitere Symptome** zur Verbesserung anzufordern

### Logik:
- **Deduktion**: Aus Diagnose folgt Symptom
- **Abduktion**: Aus beobachteten Symptomen auf Diagnose schlieÃŸen
- **Problematisch**: UnvollstÃ¤ndigkeit, WidersprÃ¼che

### Anforderungen an Diagnosesysteme:
- Umgang mit unvollstÃ¤ndigem Wissen
- PlausibilitÃ¤tsprÃ¼fung
- Erkennung von Mehrfachdiagnosen
- Kosteneffektive Symptomerhebung

## âš™ï¸ 3. Grundalgorithmus

1. Start mit **Apriori-Wahrscheinlichkeiten** aller Diagnosen
2. Modifikation durch **Symptom-Diagnose-Wahrscheinlichkeiten**
3. Auswahl der wahrscheinlichsten Diagnose

## ğŸ“ 4. Theorem von Bayes

### Grundformel:
$$P(D_i | S) = \frac{P(D_i) \cdot P(S | D_i)}{P(S)}$$

### Beispiel:
- \( P(	ext{Bronchitis}) = 0.05 \)
- \( P(	ext{Husten}) = 0.2 \)
- \( P(	ext{Husten | Bronchitis}) = 0.8 \)
- â†’ \( P(	ext{Bronchitis | Husten}) = 0.2 \)

### Probleme:
- Kombinatorische Explosion bei mehreren Symptomen
- Voraussetzung: UnabhÃ¤ngigkeit der Symptome
- Single-Fault-Annahme: nur eine Diagnose aktiv
- Statistiken mÃ¼ssen fehlerfrei & konstant sein

### Fazit:
> Anwendung des Bayes-Theorems oft theoretisch korrekt, praktisch jedoch zu ungenau.

## ğŸ§® 5. Probabilistische Diagnosebewertung

### Bewertung:
- **Pro**: erwartete + beobachtete Symptome
- **Kontra**: erwartete, aber nicht beobachtete Symptome
- **ErklÃ¤rungswert**: nicht erwartete, aber beobachtete Symptome

### ZusÃ¤tzliche Aspekte:
- PrÃ¤dispositionen
- Differentialdiagnostik

## ğŸ“Š 6. Erweiterte Modelle zur Unsicherheitsverrechnung

### ğŸ”· Dempster-Shafer-Theorie
- Unsicherheitsintervalle statt exakter Werte: \[a, b\]
- P(Diagnose | Symptom) statt P(Symptom | Diagnose)
- Vorteile:
  - ReprÃ¤sentation von Grobdiagnosen
  - Modellierung von Diagnosehierarchien
- Nachteil: hoher Rechenaufwand (\(2^n\) Diagnosemengen)

## ğŸ¥ 7. INTERNIST-Modell (siehe ChatGPT)

- Beruht auf Expertenwissen, keine exakten Wahrscheinlichkeiten
- Bewertungsfaktoren:
  - **Evoking Strength** (0â€“5)
  - **Frequency** (1â€“5)
  - **Import Value** (0â€“5)
- Diagnosen in Gruppen mit Ã¤hnlichen Merkmalen
- Bonuspunktesystem bei Mehrfachdiagnosen

## ğŸ¦  8. MYCIN-Modell (siehe ChatGPT)

- BerÃ¼cksichtigt:
  - positive & negative Evidenz
  - Symptomkombinationen (Regeln)
- Rechnet mit:
  - **Belief** & **Disbelief**
  - Ergebnis = **Certainty Factor**

## ğŸ§ª 9. MED1-Modell

- Zweistufiges Modell:
  1. Evidenzsummierung
  2. Klassifikation in 7 Klassen (z.â€¯B. wahrscheinlich, gesichert)
- Vorteil: flexible ReprÃ¤sentation
- Nachteil: komplexe Interpretation

## ğŸ” 10. Alternative AnsÃ¤tze

### ğŸ”¹ Default-Logik (Reiter)
- Arbeit mit Annahmen, Revision bei neuen Infos

### ğŸ”¹ Fuzzy-Logik (Zadeh)
- Wahrheitswerte âˆˆ [0, 1]
- Operatoren:
  - \( F(\neg A) = 1 - F(A) \)
  - \( F(A \land B) = \min(F(A), F(B)) \)
  - \( F(A \lor B) = \max(F(A), F(B)) \)

## ğŸ§¾ 11. Zusammenfassung & Fazit

- Kein Modell ist vollstÃ¤ndig zufriedenstellend.
- GrÃ¶ÃŸtes Problem: Unsichere Datenbasis
- Kompromiss:
  - **Weniger prÃ¤zise, dafÃ¼r robuster im Umgang mit Unsicherheiten**
- Modellwahl hÃ¤ngt ab von:
  - Einsatzgebiet
  - VerfÃ¼gbarkeit von Daten
  - benÃ¶tigter Genauigkeit

> ğŸ” **Empfehlung**: So viel deterministisches SchlieÃŸen wie mÃ¶glich â€“ so wenig probabilistisches wie nÃ¶tig.


# ğŸ“˜ KI-Vorlesung vom 13&14 â€“ VerstÃ¤ndliche und AusfÃ¼hrliche Zusammenfassung

## ğŸ§  Nicht-monotones SchlieÃŸen: Was ist das?

### Klassische Logik (monoton):
- Einmal abgeleitete Aussagen bleiben **immer** gÃ¼ltig, selbst wenn neue Informationen dazukommen.

### Nicht-monotone Logik:
- Neue Informationen **kÃ¶nnen** bereits gezogene Schlussfolgerungen **ungÃ¼ltig** machen.
- Typisches Beispiel aus dem Alltag: Man geht davon aus, dass VÃ¶gel fliegen kÃ¶nnen â€“ bis man einen Pinguin sieht.

### GrÃ¼nde fÃ¼r nicht-monotones SchlieÃŸen:
- Erwartungen werden Ã¼berschrieben.
- Es tauchen Ausnahmen zu Regeln auf.
- Neue Informationen widersprechen alten Annahmen.

## ğŸ” Ausnahmen & Negationen

- **Ausnahmen** blockieren das AuslÃ¶sen einer Regel.
- **Negierte Aussagen** sagen aus, dass eine Aussage **nicht** zutrifft.
- Wichtig: In der **Closed World Assumption** (z.â€¯B. in PROLOG) wird "unbekannt" als "falsch" behandelt.

## ğŸ›  Belief Revision â€“ Wie Ã¤ndert man Schlussfolgerungen?

### Ziel:
- Wenn sich Informationen Ã¤ndern, soll das System so reagieren, als hÃ¤tte es diese Info **schon immer gehabt**.

### Methoden:
1. **Alles neu berechnen** â€“ funktioniert nur bei kleinen Systemen.
2. **Backtracking** â€“ ab dem Punkt neu berechnen, an dem sich etwas geÃ¤ndert hat.
3. **Minimaler Aufwand** â€“ nur die betroffenen Schlussfolgerungen werden korrigiert.

## ğŸ”„ TMS â€“ Truth Maintenance Systems

### Typen:
- **JTMS (Justification-Based)**: Speichert direkte BegrÃ¼ndungen.
- **ATMS (Assumption-Based)**: Speichert Basisannahmen.

### Beispiel-Regeln:
- R1: A â†’ B
- R2: B â†’ C
- R3: D âˆ§ Â¬E â†’ C

## ğŸ” ZirkulÃ¤re BegrÃ¼ndungen und Schleifen

- **Problematisch**, wenn sich Schlussfolgerungen gegenseitig stÃ¼tzen (z.â€¯B. A â†’ B, B â†’ A).
- **Monotone Schleifen** sind ok â€“ **nicht-monotone** (mit Negationen) fÃ¼hren zu Endlosschleifen.

## ğŸ§© Strategien zur Schleifenbehandlung

1. **Current Support**: Nur eine BegrÃ¼ndung zÃ¤hlt, andere werden ignoriert â€“ spart Rechenaufwand.
2. **Automatische Schleifenerkennung**: 
   - z.â€¯B. im ITMS (Immediate-Check TMS)
   - Regeln, die zirkulÃ¤re Evidenz liefern kÃ¶nnten, werden markiert und ggf. blockiert.

## ğŸ§± ATMS â€“ Kontextbasiertes Denken

- Jeder Schlussfolgerung ist ein **Kontext** zugeordnet = Kombination von Basisannahmen.
- **Knotenstruktur**:
  - Basisannahme
  - GÃ¼ltigkeitskontext
  - Direkte BegrÃ¼ndungen

## ğŸ§® Temporales SchlieÃŸen

- Aussagen kÃ¶nnen **zeitabhÃ¤ngig** wahr oder falsch sein.
- Genutzt werden **modale Operatoren** wie:
  - NEXT F: ab nÃ¤chstem Zustand
  - FUTURE F: irgendwann in der Zukunft
  - GLOBALLY F: immer

## ğŸ©º Diagnostiksysteme â€“ Ãœberblick

### Wissenstypen:
- Statistisch
- Fallbasiert (Ã¤hnliche FÃ¤lle vergleichen)
- Heuristisch (Expertenwissen)
- Kausal (Ursache-Wirkung)

### Kontrollstrategien:
- VorwÃ¤rtsverkettung
- RÃ¼ckwÃ¤rtsverkettung
- Hypothesize-and-Test

## ğŸ’‰ Beispiel: MED2-System

- Verbindet viele Diagnosestrategien:
  - Verdachtsgenerierung
  - VerdachtsÃ¼berprÃ¼fung
  - Differentialdiagnostik
  - TherapievorschlÃ¤ge

## ğŸ”§ Konstruktion â€“ Der Unterschied zur Diagnostik

- Ziel: **LÃ¶sungen aktiv konstruieren**, nicht nur auswÃ¤hlen.
- Beispiele:
  - Stundenplanerstellung
  - Computer-Konfiguration
  - Molekulargenetische Planung
  - Werkstoffbearbeitung

### Zwei Haupttypen:
1. **Zuordnungsprobleme**: Bestehende Objekte richtig kombinieren.
2. **Transformationsprobleme**: Zustand verÃ¤ndern (z.â€¯B. vom Rohling zum fertigen WerkstÃ¼ck).

## ğŸ›  Planungstechniken

- **Hierarchisches Planen**: Abstrakte PlÃ¤ne werden schrittweise konkretisiert.
- **Nicht-lineares Planen**: Interaktionen zwischen Teilproblemen werden berÃ¼cksichtigt.
- **Differenzenmethode**: Differenz zwischen Ist- und Sollzustand bestimmen â†’ passenden Plan generieren.
- **Wissensbasiertes Planen**: Verwendung von vorgefertigten Planskeletten.

## ğŸ’» Beispiel: R1-System

- Konfiguration von DEC-Computern.
- Arbeitet in **6 Phasen** mit einfachen Regeln.
- Probleme:
  - Komplexe Wartung (30 Personen nÃ¶tig!)
  - Geringe Transparenz der Wissensbasis

---

# âœ… Fazit

- **Nicht-monotones SchlieÃŸen** spiegelt die RealitÃ¤t besser wider als klassische Logik.
- **Belief Revision Systeme** wie JTMS & ATMS ermÃ¶glichen flexible und nachvollziehbare Reaktion auf neue Informationen.
- **Diagnostik** und **Konstruktion** sind zwei zentrale Anwendungen der KI.
- Gute Planung erfordert **Abstraktion**, **WissensreprÃ¤sentation** und oft **heuristische Regeln**.

