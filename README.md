# KI


# K√ºnstliche Intelligenz ‚Äì Vorlesung 1 (2024)

## Modul: K√ºnstliche Intelligenz  
**Prof. Dr. Heinrich Jasper**  
**TU Bergakademie Freiberg**  

---

## Zielsetzung des Moduls

- **Erwerb von Kenntnissen und Fertigkeiten** in:
  - Grundlagen der K√ºnstlichen Intelligenz (KI)
    - Begriffsbildung
    - Methoden und Techniken
    - Anwendungsgebiete
    - Historie und Stand der Technik
  - √úbungen zur KI
    - Spezielle Themen
    - Einf√ºhrung in **PROLOG** als Programmiersprache

---

## Begriffsbildung

### Definitionen K√ºnstlicher Intelligenz
- **Systeme, die wie Menschen denken** (Haugeland, 1985)
- **Systeme, die wie Menschen handeln** (Rich & Knight, 1991)
- **Systeme, die rational denken** (Winston, 1992)
- **Systeme, die rational handeln** (Nilsson, 1998)

> **Zusammenfassung:** KI ist eine Informatikanwendung. Sie ist dem neuronalen Netzwerk unseres Gehirns nachempfunden. KI kann einen Ausschnitt menschlicher Intelligenz nachahmen. Das Besondere ist die F√§higkeit zu lernen. Das unterscheidet KI‚ÄêSysteme von herk√∂mmlichen Computerprogrammen. Statt einem Programm genau zu sagen, was es tun soll, bekommt das KI‚ÄêSystem eine Aufgabe gestellt, die es selbst√§ndig zu l√∂sen hat.

### Wichtige Merkmale
- Lernf√§higkeit
- Aufgabenbew√§ltigung ohne genaue Programmierung

---

## Motivation

- **Anwendungsfelder**:
  - Sprachverstehen (Smart Devices, GPTs)
  - Autonome Systeme (Fahrzeuge, Roboter)
  - Milit√§rtechnologien (Drohnen, Kampfmaschinen)
  - Virtuelle Welten (Spiele, VR)
- **Zielsetzung**:
  - Verstehen und Beeinflussung nat√ºrlicher Intelligenz
  - Aufbau k√ºnstlich intelligenter Systeme
  - Kombination beider Richtungen (Intellektik)

---

## Intelligente Agenten

- Begriffseinf√ºhrung durch Mind-Maps (Details folgen in sp√§teren Veranstaltungen)

---

## Einordnung der KI

### Forschungsgebiete:
- Kognition / Bildverarbeitung / Sprachverstehen
- Wissensverarbeitung / Probleml√∂sen / Analogien
- Lernen / Autonomie / Interaktion
- Genetik / Evolution

### Technologien und Systeme:
- Suchverfahren
- Funktionale, logische, objektorientierte Programmierung
- Expertensysteme
- Wissensrepr√§sentation / Logisches Schlie√üen
- Machine Learning: Clustering, Klassifikation, Assoziation
- Robotik / Agentensysteme
- Neuronale Netze
- Genetische Algorithmen

---

## Historische Grundlagen

| Bereich | Wichtige Pers√∂nlichkeiten |
| :------ | :------------------------ |
| Philosophie | Aristoteles, Hobbes, da Vinci |
| Mathematik | Boole, Turing, G√∂del |
| Betriebswirtschaft | Smith, von Neumann |
| Neurowissenschaften | Broca, Berger |
| Psychologie | Wundt, Craik |
| Technische Informatik | Zuse, Turing |
| Kontrolltheorie | Wiener, McCulloch |
| Linguistik | Chomsky, Skinner |

---

## Entwicklung der KI

### Fr√ºhzeit (1943‚Äì1955)
- K√ºnstliches Neuron
- Hebb‚Äôsche Lernregel
- Turing-Test
- Erste genetische Algorithmen

### Begriffsbildung (1956)
- **Dartmouth Workshop**: Gr√ºndung der KI als Forschungsfeld

### Enthusiasmus (1952‚Äì1969)
- Entwicklung von GPS (General Problem Solver)
- Programmiersprache **LISP**
- Lernende Programme (z.B. Schach, Geometriebeweiser)

### Erste Ern√ºchterung (1966‚Äì1973)
- F√∂rdermittelr√ºckgang wegen unerf√ºllter Erwartungen

### Wissensbasierte Systeme (1969‚Äì1990)
- Expertensysteme, Regelsysteme, Wissensrepr√§sentation

### Erfolgreiche KI-Forschung (ab 1980)
- PROLOG, neuronale Netze, autonome Systeme, Agententechnologie

### Zweiter KI-Winter (1990‚Äìca. 2010)
- Entt√§uschung √ºber allgemeine KI-Techniken

### Heute (2020+)
- Massive Fortschritte:
  - Autonome Fahrzeuge
  - Sprach- und Bild-KI (z.B. GPT, Stable Diffusion)
  - Integration in Alltagsger√§te (Waschmaschinen, Kreditsysteme)
- Gro√üe Herausforderungen:
  - Ethische und gesellschaftliche Fragen
  - Verst√§ndnis von Intelligenz und Rationalit√§t

---

## Aktuelle Anwendungen

- Autonome Computer- und Fahrzeugsysteme
- Diagnosesysteme (Medizin, Technik)
- Planungs- und Optimierungssysteme
- Robotik
- Sprachverstehen und √úbersetzung
- Wissensverarbeitung und Ontologien
- Semantische Suchen
- Emotionale Agenten
- Bio-/Neurologische Analogien
- Theoretische Forschung zu KI-Grundlagen

---


# VL2 - Intelligente Agenten ‚Äì Zusammenfassung

## Allgemeines Modell

- **Definition**: Intelligente Agenten sind Systeme, die wirklich als intelligent bezeichnet werden k√∂nnen.
- **Grundstruktur**:
  - **Agent** interagiert mit der **Umgebung**.
  - Nutzt **Sensoren** zur Wahrnehmung und **Aktuatoren** zur Ausf√ºhrung von Aktionen.

```
Agent <-> Umgebung
(Sensoren zur Wahrnehmung, Aktuatoren f√ºr Aktionen)
```

## Rationaler Agent

- **Ziel**: Auswahl von Handlungen, die die Leistungsbewertung maximieren.
- **Leistungsbewertung**: 
  - Definiert, was ein "gutes" Verhalten ist.
  - Bewertet den Erfolg eines Agenten.
- **Wichtige Aspekte**:
  - Rationalit√§t bedeutet nicht Allwissenheit oder Perfektion.
  - Lernen ist zentral f√ºr die Verbesserung der Leistung.

## Arbeitsumgebungen von Agenten (Beispiele)

| Agententyp | Leistungsbewertung | Umgebung | Aktuatoren | Sensoren |
|:---|:---|:---|:---|:---|
| Medizinisches Diagnosesystem | Gesunder Patient, minimale Kosten/Klagen | Patient, Krankenhaus, Team, Medikamente | Fragen, Untersuchungen, Diagnosen, Empfehlungen | Tastatureingaben, Symptome, Befunde |
| Satellitenbildanalyse | Korrekte Bildkategorisierung | Downlink vom Satelliten | Anzeige der Kategorisierung | Farbpixelarrays |
| Packroboter f√ºr Teile | Prozentsatz korrekter Teile | Flie√üband mit Teilen, Beh√§lter | Arm und Greifhand | Kamera, Winkelsensoren |
| Raffinerie-Controller | Maximale Reinheit/F√∂rdermenge/Sicherheit | Raffinerie, Arbeiter | Ventile, Pumpen, Heizungen, Anzeigen | Temperatur-, Druck-, chemische Sensoren |
| Interaktiver Englischlehrer | Maximale Testergebnisse | Sch√ºler, Pr√ºfungskommission | √úbungen, Vorschl√§ge, Korrekturen | Tastatureingabe |

### Weitere Beispiele:
- **Drohne**: Mission auf Planetenoberfl√§che, Sensor- und Waffensteuerung.
- **Autonomes Fahrzeug**: Gute Fahrt von A nach B, Kommunikation mit Umwelt und anderen Fahrzeugen.

## Kategorisierung von Arbeitsumgebungen

- **Vollst√§ndig vs. Teilweise beobachtbar**: Sind alle Informationen der Umgebung verf√ºgbar?
- **Deterministisch vs. Stochastisch**: Gibt es Zufallseinfl√ºsse?
- **Episodisch vs. Sequenziell**: Einzelne Entscheidungen oder verkettete?
- **Statisch vs. Dynamisch**: Ver√§ndert sich die Umgebung unabh√§ngig vom Agenten?
- **Diskret vs. Stetig**: Endliche vs. kontinuierliche Zust√§nde.
- **Einzelagent vs. Multiagenten**: Arbeitet der Agent alleine oder kooperativ?

## Struktur eines Agenten

- **Architektur**: Physische Komponenten wie Sensoren, Aktuatoren.
- **Programm**: Logik und Algorithmen, die das Verhalten steuern.

## Typen von Intelligenten Agenten

1. **Einfache Reflex-Agenten**:
   - Entscheidung nur anhand aktueller Wahrnehmung.
   - Realisiert √ºber Bedingungs-/Aktions-Tabellen.

2. **Modellbasierte Reflex-Agenten**:
   - F√ºhren ein Modell der Welt basierend auf bisherigen Wahrnehmungen.
   
3. **Zielbasierte Agenten**:
   - Planen Handlungen, um definierte Ziele zu erreichen.

4. **Nutzenbasierte Agenten**:
   - Bewerten verschiedene Zust√§nde und w√§hlen den besten.

5. **Lernende Agenten**:
   - Verbesserung der Leistung durch Feedback und Lernalgorithmen.

## Reflexagenten ‚Äì Probleme

- **Table-Driven Agent**:
  - Realisierung √ºber eine Tabelle, die Wahrnehmungen Aktionen zuordnet.
  - Unpraktikabel: Bei gro√üer Datenmenge explodiert die Gr√∂√üe der Tabelle exponentiell.

- **Beispiel**:
  - Sensor liefert 27 MB/Sekunde, 1 Stunde Fahrzeit ‚áí gigantische Tabelle (mehr als Atome im beobachtbaren Universum).

## Agenten und Wissen

- **Wissensbasiertes System**:
  - Enth√§lt eine **Wissensbasis**, ein **Inferenzsystem**, ein **Wissensmodell** und nutzt eine **Modellierungssprache**.

- **Verhaltensbasiertes System**:
  - Direktes Handeln durch Regeln, ohne tiefgreifende Wissensrepr√§sentation.

### √úbersicht:

| Kategorie | Beschreibung |
|:---|:---|
| K√ºnstlich-intelligente Systeme | √úberbegriff |
| Wissensbasierte Systeme | Nutzung von explizitem Wissen |
| Verhaltensbasierte Systeme | Direkte Aktion ohne tiefes Wissen |
| Expertensysteme | Spezialwissen + Schlussfolgern auf engen Aufgabengebieten |

## Expertensysteme (XPS)

- **Ziel**: Simulation des Fachwissens und der Probleml√∂sungsstrategien von Experten.
- **Vorgehen**:
  - Wissen wird formalisiert und maschinell nutzbar gemacht.
  - Wissensingenieur implementiert die Probleml√∂sungsstrategien.
  
- **Vorteil**:
  - √Ñnderung und Wartung einfacher als bei konventionellen Programmen durch klare Trennung von Wissen und Strategie.

## Komponenten eines Expertensystems

- **Benutzungsschnittstelle**: Interaktion mit dem Benutzer.
- **Interviewerkomponente**: Aufnahme neuer Fakten.
- **Erkl√§rungskomponente**: Begr√ºndung von Entscheidungen.


- **Inferenzsystem**: Schlussfolgerung von neuen Erkenntnissen.
- **Wissensakquisitionskomponente**: Integration neuen Wissens.
- **Wissensbasis**: Zentrale Sammlung von Fakten und Regeln.
- **Wissensmodell** (Knowledge Representation Model): Die Art und Weise, wie Wissen im System dargestellt wird.
  - Beispiele:
  - Regeln (Wenn-Dann-Form)
  - Frames (Objekte mit Attributen)
  - Ontologien (strukturierte Begriffe und Relationen)
  - Semantische Netze oder Logikbasierte Modelle
- **Modelierungssprache**: Eine formale Sprache zur Darstellung von Wissen.
  - Beispiele:
  - Prolog
  - OWL (Web Ontology Language)
  - LISP, CLISP


# VL3 Exkurs: PROLOG ‚Äì Logikprogrammierung in der K√ºnstlichen Intelligenz

## üéØ Ziel
- Wissensverarbeitung mittels **Logikprogrammierung**
- Einf√ºhrung in die Programmiersprache **PROLOG** (*Programming in Logic*)

## üìö Historischer Hintergrund

| Forscher        | Beitrag                                                                 |
|----------------|--------------------------------------------------------------------------|
| Frege (~1880)  | Begriffswelt als mathematische Sprache                                   |
| Herbrand, Skolem, G√∂del (1920‚Äì1935) | Mathematischer Beweisaufbau                         |
| Robinson (1965)| Resolution (Schlussfolgerung aus Axiomen)                                |
| Colmerauer (1972)| Entwicklung von PROLOG mit Resolution & Unifikation                    |
| Kowalski (~1982)| ‚ÄûAlgorithm = Logic + Control‚Äú                                           |

## üî§ Grundelemente von PROLOG

### 1. **Fakten**
```prolog
auto.
name(bernd).
vater_von(bernd, erwin).
```

### 2. **Regeln**
```prolog
vorfahr_von(X,Y) :- vater_von(X,Y).
vorfahr_von(X,Y) :- mutter_von(X,Y).
```

### 3. **Abfragen**
```prolog
?- vater_von(bernd, X).
X = erwin.
```

## üîç PROLOG-Prinzipien

### a) Fakten
```prolog
fleisch(schnitzel).
fisch(aal).
verheiratet(bernd, ilse).
```

### b) Anfragen
```prolog
?- fleisch(schnitzel).  % yes
?- fleisch(aal).        % no
?- fisch(X).            % X = aal; X = scholle
```

### c) Regeln
```prolog
gesund(X) :- obst(X).
obst(apfel).
```

### d) Suchstrategie
- Tiefensuche mit Backtracking
- Regelreihenfolge wichtig!
- Achtung: Kann zu Nicht-Terminierung f√ºhren.

## üß± Objekte in PROLOG

### a) Atome, Zahlen, Strukturen
```prolog
geboren(fritz, 1, 10, 1938).
geboren(fritz, datum(1,10,1938)).
```

### b) Operatoren
```prolog
1 + 3 * 4  => +(1, *(3,4))
```

### c) Listen
```prolog
[]
[1]
[x,y]
[a|[b|[c]]]
```

### d) Variablen
```prolog
Vater
_vater
_
```

### e) Terme
```prolog
?- istVatervon(zeus, ares). % yes
?- 2+3 = 5.                 % no
```

## üß† Fakten und Regeln

### 3. **Fakten**
```prolog
katze(mieze).
```

### 4. **Regeln**
```prolog
tier(X) :- katze(X), lebt(X).
```

## üîÅ Resolutionsprinzip
- Unifikation:	Struktureller Vergleich zweier Terme
- Substitution:	Bei erfolgreicher Unifikation werden die Variablen durch konkrete Werte ersetzt. Das nennt man Substitution.
- Resolution:	Anwendung von Regeln/Fakten durch Unifikation + Substitution
- Backtracking:	R√ºckverfolgung zur n√§chsten Alternative bei Fehlschlag



## üîÅ PROLOG-Prozeduren & Programme

### Definition:
- Programm = Klauseln (Fakten + Regeln)
- Prozedur = gleiche Kopf-Funktoren
- Anfrage = spezielle Klausel

## üìä Semantik von PROLOG

- Semantik = Beweise im SLD-Resolutionsbaum \\
SLD: Selektive lineare Definite-Clause-Resolution

Aufl√∂sung erfolgt durch sukzessives Ersetzen von Zielen durch Regelk√∂pfe

Backtracking, sobald keine Regel anwendbar ist

Liefert Beweise in Form eines Herleitungsbaums

## ‚úÖ Zusammenfassung

- PROLOG: deklarative Sprache zur Wissensverarbeitung
- Prinzipien: Fakten, Regeln, Abfragen, Backtracking, Unifikation
- Anwendung: symbolische KI, Expertensysteme, Sprache



# VL4 ü§ñ K√ºnstliche Intelligenz ‚Äì Probleml√∂sung durch Suchen

## üîç Probleml√∂sender Agent

- Zielbasiert: Ziel ist durch einen oder mehrere w√ºnschenswerte Zust√§nde definiert.
- Keine Begrenzung der Zust√§nde im Voraus.
- Ziel: Finde eine Aktionsfolge, die zum Ziel f√ºhrt und f√ºhre sie aus.

### Parameter zur Problemformulierung:
- Wie ist das Ziel definiert?
- Welche Zust√§nde sind relevant?
- Welche Aktionen sind m√∂glich?

### Begriffe:
- Suche = Ermittlung der Aktionsfolge
- Agentenmodell: **Formulieren ‚Äì Suchen ‚Äì Ausf√ºhren**
- **Uninformierte Suche**: keine Information √ºber Qualit√§t der Zust√§nde
- **Informierte Suche**: Bewertung der Zust√§nde m√∂glich

---

## üß† Einfacher Probleml√∂ser (Pseudocode)

```pseudo
function EinfacherProbleml√∂ser(percept) returns action
    static: seq ‚Üê []
    state ‚Üê update_state(state, percept)

    if seq is empty:
        goal ‚Üê formulate_goal(state)
        problem ‚Üê formulate_problem(state, goal)
        seq ‚Üê search(problem)

    if seq not empty:
        action ‚Üê first(seq)
        seq ‚Üê rest(seq)

    return action
end
```

---

## üìê Wohldefinierte Probleme

- **Ausgangszustand**
- **Nachfolgerfunktion**: liefert `<Aktion, Nachfolgerzustand>`
- **Zieltest**: pr√ºft Zielzustand
- **Pfadkosten**: Summe der Aktionskosten

**Zustandsraum** = gerichteter Graph

**Optimale L√∂sung** = L√∂sung mit minimalen Pfadkosten

---

## ‚ôüÔ∏è Beispielprobleme

### üß© 8-Puzzle

- Zust√§nde: Positionen der Zahlen & Leerfeld
- Nachfolgerfunktion: Bewegung des Leerfelds (oben, unten, links, rechts)
- Zieltest: erreicht Zielanordnung
- Pfadkosten: 1 pro Bewegung

### üë∏ 8-Damen-Problem

- Ziel: 8 Damen auf Schachbrett, keine bedroht eine andere
- Alternative Zustandsdarstellung reduziert Anzahl zu pr√ºfender Zust√§nde

---

## üöö Praktische Probleme

- Routenplanung, Logistik, Handlungsplanung
- Schaltungsdesign
- Roboternavigation
- Internet-Suche

---

## üå≤ Suchb√§ume und Strategien

### Definition eines Suchbaums:

- Wurzel = Ausgangszustand
- Kinder = Nachfolger gem√§√ü Nachfolgerfunktion
- Strategie bestimmt Reihung der Expansion

```pseudo
function tree-search(Problem, Strategie)
    initialisiere Suchbaum mit Ausgangsknoten
    while true:
        wenn keine Kandidaten: return Fehler
        w√§hle Knoten laut Strategie
        wenn Ziel erreicht: return L√∂sung
        sonst: erweitere Knoten
```

---

## üîÑ Uninformierte Suchstrategien

### 1. Breitensuche (BFS)
- Vollst√§ndig, optimal
- Zeit- & Speicherkomplexit√§t: O(b^d)

| Tiefe | Knoten    | Zeit         | Speicher    |
|-------|-----------|--------------|-------------|
| 2     | 1,100     | 0,1 Sek      | 1 MB        |
| 6     | 10^7      | 19 Minuten   | 10 GB       |
| 12    | 10^13     | 35 Jahre     | 10 PB       |

---

### 2. Tiefensuche (DFS)
- Nicht vollst√§ndig, nicht optimal
- Geringer Speicherbedarf

### 3. Iterative Deepening
- Kombiniert BFS & DFS

### 4. Bidirektionale Suche
- Zwei gleichzeitige Suchen von Start und Ziel
- Komplexit√§t: O(b^(d/2))

### 5. Weitere Strategien
- Uniforme-Kosten-Suche
- Begrenzte-Tiefen-Suche
- Iterative-Tiefen-Suche

---

## üß† Informierte Suchstrategien

- Nutzung von Heuristiken h(n)

### Greedy Best-First Search
- W√§hlt immer den Knoten mit dem kleinsten gesch√§tzten Abstand zum Ziel. h(n)
- Risiko: Sackgassen
- Schnell, aber nicht optimal, da es Abk√ºrzungen √ºbersehen kann.

### A*-Suche
- f(n) = g(n) + h(n)
- g(n): Kosten bisher
- h(n): gesch√§tzte Kosten zum Ziel
- Kombination aus optimal & effizient
- Suche mit Blick auf Vergangenheit und Zukunft.

---

## üßó Lokale Suche & Optimierung

### Hillclimbing
- Folge dem besten lokalen Nachfolger mit dem besten Heuristikwert.
- Gefahr: lokales Optimum

### Simulated Annealing
- Erlaubt gelegentlich auch schlechtere L√∂sungen
- Nutzt Temperaturparameter T und Wahrscheinlichkeit zur Akzeptanz

---

## üß¨ Evolution√§re Algorithmen (EA)

- Simulation biologischer Evolution
- Individuen = L√∂sungskandidaten
- Fitnessfunktion = Bewertung

### Hauptkomponenten:
- **Rekombination r**: Kombination zweier Individuen
- **Mutation m**: zuf√§llige Ver√§nderung
- **Selektion s**: Auswahl fitter Individuen
- **Abbruchbedingung z**

### Ablaufschema:
```text
Initialisierung: P(0)
Bewertung: f(a_i)
while !Abbruch:
    Rekombination
    Mutation
    Bewertung
    Selektion
    t = t + 1
```

---

## üß™ Evolutionsstrategien (ES)

- Ein anderer Typ von evolution√§rem Algorithmus, entwickelt in Deutschland (Rechenberg, Schwefel).
- üß† Besonderheiten:
  - Fokus auf reale Zahlen (nicht Bitstrings!)
  - St√§rker betont: Mutation statt Crossover
  - Anpassung der Mutationsst√§rke √ºber Zeit (selbstadaptiv)
- Besonders gut f√ºr kontinuierliche Optimierungsprobleme (z.‚ÄØB. Maschinensteuerung, Robotik)

### Beispiel:
- F(x1,x2) = x1¬≤ + x2¬≤
- Individuum = (x1, x2, s1, s2)
- Mutation und Rekombination √ºber Strategieparameter

---

## üß¨ Genetische Algorithmen (GA)

- Bitstring-Repr√§sentation der Individuen als Genotyp
- Operatoren: **Crossover**, **Mutation**, **Selektion**
- K√∂nnen auch in Problemen ohne exakte mathematische Beschreibung eingesetzt werden
- Suche im diskreten Raum
- Nutzen: Scheduling (z.‚ÄØB. Flugpl√§ne)
### Crossover:
- Zwei Eltern ‚Üí Kind durch Bittausch an zuf√§lliger Stelle

### Mutation:
- Flip einzelner Bits mit geringer Wahrscheinlichkeit

---

## üìå Fazit

- Suche ist zentrales Konzept in der KI
- Informierte Strategien und heuristische Verfahren bieten Effizienzvorteile
- Lokale und evolution√§re Verfahren erg√§nzen die klassischen Suchalgorithmen bei komplexen Problemen


# VL5 üìö K√ºnstliche Intelligenz ‚Äì Wissensrepr√§sentation & Logik

## ü§ñ Logisch schlie√üender Agent

ein Agent, der Wissen √ºber die reale Welt enth√§lt, das
- aus der Beschreibung m√∂glicher Zust√§nde, Operationen und Zusammenh√§nge besteht,
- zur Ableitung von Zustandseigenschaften und Operationsfolgen genutzt werden kann,
- ver√§ndert bzw. gelernt werden kann.

### Komponenten:
- **Wissensbasis**: Menge von S√§tzen √ºber die reale Welt
- **Inferenzverfahren**: Ableitung neuer S√§tze
- **Wissensrepr√§sentationssprache**:
  - **Syntax**: Repr√§sentationen im Agenten
  - **Semantik**: Fakten der realen Welt


- Beweis: Aufzeichnung der Anwendung von Schlussregeln eines Inferenzverfahrens
- Theorie: Menge der aus einem Kalk√ºl ableitbaren Formeln
---
## Aussagelogik
Behandelt aussagenlogische Variablen, die entweder wahr oder falsch sind.
Man arbeitet mit einfachen Aussagen und Verkn√ºpfungen wie UND, ODER, NICHT, ‚Üí (Implikation)

### Hilbert-Axiomensystemen (Aussagelogik):
Das Hilbert-System (benannt nach David Hilbert) ist ein axiomatisches System, das mit:

- einer kleinen Anzahl von Axiomen (Grundformeln), und
  - De Morgen, Verschmelzung, Konjunktion, ...
- wenigen Schlussregeln (v.‚ÄØa. Modus Ponens)

jede g√ºltige Aussage der Aussagenlogik beweisbar machen will.

Eigenschaften: vollst√§ndig, **entscheidbar**, wiederspruchsfrei, monoton, unabh√§ngig

## Pr√§dikatenlogik
- Erweitert die Aussagenlogik um Objekte, Eigenschaften und Quantoren.
- Hier kann man √ºber Dinge in der Welt sprechen ‚Äì nicht nur √ºber Wahrheitswerte.

- Eigenschaften: vollst√§ndig, **nicht entscheidbar**, wiederspruchsfrei, monoton, unabh√§ngig
  - nicht entscheidbar: Es gibt kein Verfahren, das f√ºr alle Aussagen entscheidet, ob sie g√ºltig sind (wegen der Unendlichkeit von Dom√§nen)


Beide Logiksysteme sind vollst√§ndig, widerspruchsfrei, monoton und unabh√§ngig.
Aber nur die Aussagenlogik ist entscheidbar ‚Äì die Pr√§dikatenlogik nicht.
# VL 6
- Eine **Klausel** ist eine ODER-Verkn√ºpfung (Disjunktion) von Literalen.
  - vollst√§ndig, nicht entscheidbar
- Eine **Hornklausel** ist eine spezielle Klausel mit h√∂chstens einem positiven Literal.
- Hornklauseln sind Grundlage von Prolog und erm√∂glichen effizientes logisches Schlie√üen.
  - Sie erm√∂glichen einfache Implementierung logischer Systeme wie Expertensysteme oder Regelwerke
  - nicht vollst√§ndig, nicht entscheidbar

## Ableitungsstrategien
### Vorw√§rtsverkettung:
- Startet mit Fakten, leitet neue ab, bis das Ziel erreicht ist.
- Konfliktl√∂sung: Priorit√§ten, Reihenfolge, Spezifit√§t.
  - Wenn mehrere Regeln gleichzeitig anwendbar sind, spricht man von einem Konflikt. Eine Konfliktl√∂sungsstrategie entscheidet, welche Regel zuerst ausgef√ºhrt wird.
### R√ºckw√§rtsverkettung:
- Man beginnt mit einer Anfrage oder Hypothese und sucht r√ºckw√§rts, ob es Regeln und Fakten gibt, mit denen man das Ziel beweisen kann.
- Vergleich: √Ñhnlich zu Prologs Tiefensuche.

## Regelbasiertes System
Ein regelbasiertes System (auch Produktionssystem genannt) ist ein wissensbasiertes System, das automatisch Schlussfolgerungen zieht und Entscheidungen trifft, indem es Regeln auf bekannte Fakten anwendet.

Ein regelbasiertes System besteht aus
- Datenbasis mit den g√ºltigen Fakten
- Regeln zur Herleitung neuer Fakten / Ausf√ºhrung von Aktionen
- Regelinterpreter zur Steuerung des Herleitungs-/Ausf√ºhrungsprozesses

Prinzipielle Abarbeitungsmechanismen eines Regelinterpreters
- Vorw√§rtsverkettung: feuere Regeln solange, bis sich die Datenbasis (eine Menge von Fakten) nicht mehr √§ndert
oder Abbruchbedingung erf√ºllt ist
- R√ºckw√§rtsverkettung: Vom Ziel ausgehend, werden Vorbedingungen etabliert; pr√ºfe, ob Vorbedingungen
erf√ºllbar (Fakten oder R√ºckfragen beim Nutzer), ansonsten: Vorbedingungen sind das n√§chste Ziel.


Was ist eine spezifischere Regel?
- Eine spezifischere Regel hat mehr Bedingungen auf der linken Seite (Pr√§misse) ‚Üí sie ist eingeschr√§nkter, wird also selten angewendet, aber liefert gezieltere Schl√ºsse.


## Frames
Idee: Aussagen √ºber ein Objekt strukturiert zusammenfassen
- Ein Frame ist eine Art Datenstruktur, die ein Konzept, Objekt oder eine Situation beschreibt ‚Äì √§hnlich einem Objekt in der Objektorientierten Programmierung.

- Ein Frame besteht aus:
  - Slots (Attribute, Eigenschaften, Fragen)
  - Slot-Filler (Werte, Regeln, andere Frames)

- Sie sind vererbbar und k√∂nnen Prozeduren enthalten (Programme, die Eigenschaften eines Objekts zugeordnet sind)

- Frames eignen sich besonders gut zur repr√§sentativen Darstellung realer Objekte und sind leicht erweiterbar.
- FRL (Frame Representation Language) ist eine spezielle Repr√§sentationssprache, die entwickelt wurde, um Frames formal darzustellen und zu verarbeiten

### Kognitive Wurzel:
Der Begriff ‚Äûkognitive Wurzel‚Äú weist darauf hin, dass Frames auf Beobachtungen der menschlichen Kognition beruhen ‚Äì also wie Menschen Wissen speichern, organisieren und abrufen.

## Semantische Netze
Ein semantisches Netz ist eine graphbasierte Wissensdarstellung, bei der Konzepte (Knoten) und deren Beziehungen (Kanten) visuell und logisch dargestellt werden.

- Eigenschaften:
  - Knoten = Begriffe/Objekte (z.‚ÄØB. ‚ÄûHund‚Äú, ‚ÄûTier‚Äú)
  - Kanten = Beziehungen (z.‚ÄØB. ‚Äûist-ein‚Äú, ‚Äûhat-Teil‚Äú, ‚Äûlebt-in‚Äú)
  - Beziehungen sind oft gerichtet: von Subjekt zu Objekt

- Nutzen:
  - Intuitive Visualisierung von Wissen
  - Wird oft f√ºr Sprachverarbeitung und Ontologien genutzt

Ein semantisches Netz stellt Wissen in Form eines gerichteten Graphen dar ‚Äì mit Knoten als Objekten und Kanten als Relationen. Es eignet sich gut zur Vererbung und Konzeptdarstellung.

### KL-ONE
KL-ONE ist eine formale Weiterentwicklung semantischer Netze.
Es ist ein strenges, logikbasiertes Klassifikationssystem, das Begriffshierarchien definiert ‚Äì also ein Begriffsnetz mit Logikregeln.

- Grundlage f√ºr viele moderne Ontologie-Systeme wie OWL


## Constrains Netze
Ein Constraint-Netz ist eine graphische Darstellung eines Constraint-Satisfaction-Problems (CSP).
Es zeigt, welche Variablen vorkommen, welche Wertebereiche (Dom√§nen) sie haben, und welche Einschr√§nkungen (Constraints) zwischen ihnen bestehen.

Nutze:
  - Stundenpl√§ne
  - Sudoku
  - Routenplanung

# VL 7
## Was ist ein Plan-Agent?
![alt text](image.png)

Merkmale:
- Hat ein Modell der Welt (Zust√§nde, Aktionen, Effekte)
- Nutzt logische Repr√§sentation (z.‚ÄØB. Situationskalk√ºl)
- Wendet Planungsalgorithmen an

## Situationskalk√ºl
Zur formalen Beschreibung von Handlungen und deren Effekten
![alt text](image-2.png)
üò∞ Herausforderung: Frame-Problem
‚Üí Wie stellt man formell dar, was sich nicht √§ndert, wenn eine Aktion ausgef√ºhrt wird?

Beispiel: Wenn man die T√ºr √∂ffnet, bleiben Tisch, Stuhl, Fensterzustand etc. gleich ‚Äì das muss extra ber√ºcksichtigt werden.


## Was ist ein Planungsalgorithmus?
Ein Planungsalgorithmus ist ein Verfahren, das eine Reihenfolge von Aktionen erstellt, um einen Zielzustand von einem Startzustand aus zu erreichen. Typische Planalgorithen: A*-Planung, STRIPS

- Gegeben: Start-, Zielzustand, Operationen
- Erzeugen eines Intialen Planes
- Suche im Zustandsraum ‚Üí finde Pfad von Start ‚Üí Ziel
- Erzeuge Aktionsfolge (Plan)
- √úberpr√ºfe w√§hrend Ausf√ºhrung: Ist der aktuelle Zustand wie erwartet?
- Bei Abweichung: Replanung

## Initialer Plan
Ein initialer Plan ist der erste Vorschlag oder Ablauf von Aktionen, der erstellt wird, um ein bestimmtes Ziel zu erreichen.

Ein Agent kann erkennen, dass der initiale Plan nicht mehr g√ºltig ist, wenn:
| Methode                               | Beschreibung                                                                                         |
| ------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| **Plan√ºberpr√ºfung (Plan Monitoring)** | W√§hrend der Ausf√ºhrung pr√ºft der Agent regelm√§√üig, ob alles wie geplant l√§uft.                       |
| **Soll-Ist-Vergleich**                | Der Agent vergleicht erwartete Zust√§nde mit aktuellen Zust√§nden.                                     |
| **Fehlschlag beim Ausf√ºhren**         | Wenn eine Aktion nicht m√∂glich ist (z.‚ÄØB. T√ºr ist blockiert), erkennt der Agent: Plan ist gebrochen. |
| **Sensorfeedback**                    | Neue Informationen machen den Plan veraltet oder falsch.                                             |

In solchen F√§llen wird ein neuer Plan erzeugt = Replanung

# VL 8
## Lernender Agent
Ein Agent, der seine Eingaben nicht nur zur Steuerung seiner unmittelbaren Ausgaben verwendet sondern auch zur Ver√§nderung (Verbesserung) seiner zuk√ºnftigen Verhaltensweise.

- Formen des Lernens:
  - Speichern von Erfahrungen, Klassifizierung, Verallgemeinerung, Theoriebildung.
  - Beispiele: Navigation, Schach, Sprachverarbeitung.

- Komponenten:
  - Probleml√∂ser: Steuert das aktuelle Verhalten.
  - Lernkomponente: Passt Wissen anhand von R√ºckmeldungen an.
  - Kritiker: Bewertet Erfolg/Misserfolg.
  - Problemgenerator: Erzeugt Trainingsdaten oder Testf√§lle.

- Lernarten:
  - √úberwacht (gelabelte Daten), Verst√§rkend (Belohnung/Strafe), Un√ºberwacht (Clustering).

### Aufgabenstellungen und Algorithmen
- **Vorhersage** (Regressionsaufgaben):
    Ziel: Funktion f(x)f(x) approximieren (z. B. mittels linearer Regression).
    - Lernkurve: Anzahl korrekt bearbeiteter Testbeispiele bei gegebener Anzahl von
Trainingsbeispielen
    - Fehlerfunktion e(h) = P(h(x) ‚â† f(x)) ist zu minimieren
- **Klassifikation**: beobachtete Situation (Sensordaten) einer gegebenen Klasse zuordnen.
  - Arten von Classifiern
    - Entscheidungsb√§ume
    - Regessionsb√§ume etc. (a.a.O.)
    - Semantische Netze etc. (a.a.O.)
    - Multidimensionale Zuordnungen

  - **Entscheidunsb√§ume**: Ein Entscheidungsbaum ist ein baumartiges Klassifikationsmodell, das rekursiv Attribute ausw√§hlt, um Daten in Klassen zu unterteilen. Die Attributauswahl basiert z.‚ÄØB. auf Informationsgewinn (Entropie).

    - üéØVorteile von Entscheidungsb√§umen
      - Einfach zu verstehen und interpretieren
      - K√∂nnen symbolisches Wissen erzeugen
      - Arbeiten gut mit kategorischen und numerischen Daten
      - Keine Annahme √ºber Datenverteilung n√∂tig

    - ‚ö†Ô∏è Nachteile
      - Overfitting, wenn Baum zu tief ist
      - Instabil gegen√ºber kleinen √Ñnderungen in den Daten
      - Pruning (Beschneiden) notwendig, um Generalisierung zu verbessern


  - **kNN (k-Nearest Neighbors)**: kNN ist ein klassifikationsbasiertes Lernverfahren, das eine neue Eingabe auf Basis der k n√§chsten Trainingsbeispiele klassifiziert. Es ist einfach, nicht-parametrisch, aber rechenintensiv beim Vorhersagen.

  Wie funktioniert kNN?
  - Du hast eine Menge gelabelter Datenpunkte (Trainingsdaten).
  - F√ºr einen neuen, unbekannten Punkt:
    - Berechne den Abstand zu allen Trainingspunkten (z.‚ÄØB. euklidisch).
    - W√§hle die k n√§chstgelegenen Nachbarn.
    - Mehrheitsabstimmung (Voting): Die Klasse, die am h√§ufigsten unter den k Nachbarn vorkommt, wird zugewiesen.

### Clustering:
Clustering ist ein Verfahren des un√ºberwachten Lernens, bei dem Datenobjekte in Gruppen (Cluster) eingeteilt werden, sodass:

- Objekte innerhalb eines Clusters m√∂glichst √§hnlich sind
- Objekte zwischen Clustern m√∂glichst unterschiedlich

‚úÖ Keine Klassenlabels notwendig! \\
Bsp.: Kunden in Gruppen mit √§hnlichem Kaufverhalten einteilen

#### Wie funktioniert k-Means?
k-Means ist ein iteratives Clustering-Verfahren, das Daten in k Cluster unterteilt. \\
Ziel: Minimierung der Summe der Abst√§nde zwischen Datenpunkten und ihrem jeweiligen Cluster-Zentrum (Centroid)

üîÅ Ablauf des k-Means-Algorithmus:
- W√§hle k: Anzahl der Cluster
- Initialisiere k Zentren zuf√§llig
- Zuordnungsschritt (Assignment):
- Weise jeden Punkt dem n√§chsten Zentrum zu (z.‚ÄØB. nach euklidischer Distanz)
- Update-Schritt:
- Berechne f√ºr jeden Cluster das neue Zentrum (Mittelwert der zugewiesenen Punkte)
- Wiederhole 3 & 4, bis sich die Zentren nicht mehr √§ndern (Konvergenz)

### Lernen logischer Formeln
Ziel: Generierung logischer Hypothesen, die Trainingsdaten konsistent abbilden.
### Lernen besseren Verhaltens
- K√ºnstliche Neuronale Netze (KNN/ANN):
    - Prinzip: Anpassung von Gewichten durch Backpropagation (Fehlerr√ºckf√ºhrung).
    - Deep Learning: Mehrschichtige Netze f√ºr komplexe Mustererkennung (z. B. Bilderkennung).
- Verst√§rkendes Lernen:
    - Ziel: Maximierung einer Belohnungsfunktion durch Exploration/Exploitation.
    - Beispiel: Robotersteuerung, Spielstrategien (AlphaGo).

# VL 9
## ‚úÖ Was ist ein k√ºnstliches Neuron?

Ein **Neuron** ist die kleinste Recheneinheit in einem neuronalen Netz.  
Es empf√§ngt Eingaben, multipliziert sie mit Gewichten, addiert einen Bias und gibt das Ergebnis √ºber eine **Aktivierungsfunktion** weiter.

### üîß Aufbau eines Neurons:

![alt text](image-4.png)

- Eingaben: `x‚ÇÅ, x‚ÇÇ, ..., x‚Çô`
- Gewichte: `w‚ÇÅ, w‚ÇÇ, ..., w‚Çô`
- Bias: `b` (Verschiebung der Aktivierung)
- Suchfunktion: `z = ‚àë(w·µ¢ * x·µ¢) + b` Die Suchfunktion ist die gewichtete Summenbildung der Eingabewerte.
Sie bestimmt, wie stark ein Neuron aktiviert wird, bevor die Aktivierungsfunktion angewendet wird.
- Aktivierungsfunktion: `a = f(z)` Die Aktivierungsfunktion nimmt den Ausgabewert der Suchfunktion und entscheidet, wie stark das Neuron feuert (also welchen Wert es weitergibt).

### üéõÔ∏è Typische Aktivierungsfunktionen:

| Funktion   | Formel                         | Beschreibung                        |
|------------|--------------------------------|-------------------------------------|
| Sigmoid    | `1 / (1 + e^(-z))`             | Werte zwischen 0 und 1              |
| Tanh       | `(e^z - e^-z) / (e^z + e^-z)`  | Werte zwischen -1 und 1             |
| ReLU       | `max(0, z)`                    | Beliebt, effizient, sparsam         |

---

## ü§ñ Neuron vs. Perzeptron

| Merkmal                 | Neuron (modern)                        | Perzeptron (klassisch)              |
|-------------------------|----------------------------------------|-------------------------------------|
| Aktivierungsfunktion    | ReLU, Sigmoid, Tanh (differenzierbar) | Schwellenwertfunktion (0/1-Ausgabe)        |
| Differenzierbar         | ‚úÖ Ja                                  | ‚ùå Nein                              |
| F√ºr Backpropagation     | ‚úÖ Ja                                  | ‚ùå Nein                              |
| Komplexe Aufgaben       | ‚úÖ Mehrschichtnetze m√∂glich            | ‚ùå Nur lineare Trennung              |

**Merksatz:**  
> Das Perzeptron ist die Urform des Neurons mit harter Schwelle.  
> Ein modernes Neuron nutzt differenzierbare Aktivierungsfunktionen und ist trainierbar.

---

## üß± Woraus besteht eine Schicht?

Eine **Schicht (Layer)** ist eine **Gruppe von Neuronen**, die gleichzeitig arbeiten und ihre Ausgaben an die n√§chste Schicht weitergeben.

### üß© Typen von Schichten:

1. **Eingabeschicht (Input Layer)**  
   ‚Üí Nimmt Rohdaten auf

2. **Verborgene Schicht(en) (Hidden Layer)**  
   ‚Üí Berechnungsschritte mit Aktivierungen

3. **Ausgabeschicht (Output Layer)**  
   ‚Üí Liefert Klassifikation oder Regressionswert

Ein neuronales Netz besteht aus einer Eingabeschicht (Puffer), einer oder mehreren verborgenen Schichten (Assoziierung) und einer Ausgabeschicht (Antwort).
Die Assoziierungsschicht verarbeitet die Daten und ‚Äûlernt‚Äú die Merkmale zur Klassifikation oder Entscheidung.

## üß† Klausur-Merks√§tze:

- Ein **Neuron** = gewichtete Summe + Bias ‚Üí Aktivierungsfunktion
- Das **Perzeptron** ist eine Vorform mit Schwellwertfunktion
- Eine **Schicht** besteht aus mehreren Neuronen ‚Äì das Netz aus mehreren Schichten


## Was ist Backpropagation?
Backpropagation (R√ºckw√§rtsausbreitung) ist ein Trainingsverfahren f√ºr neuronale Netze, bei dem die Gewichte so angepasst werden, dass der Fehler (Loss) zwischen dem vorhergesagten und dem tats√§chlichen Wert minimiert wird.

Neuronale Netze bestehen aus vielen Schichten ‚Äì der Fehler der Vorhersage (z.‚ÄØB. falsche Klasse) muss r√ºckw√§rts durch das Netz propagiert werden, damit jede Gewichtung entsprechend angepasst werden kann.


Anforderungen f√ºr Backpropagation:
- Aktivierungsfunktionen m√ºssen differenzierbar sein (z.‚ÄØB. Sigmoid, ReLU)
- Der Fehler muss mit einer Kostenfunktion (Loss Function) messbar sein
- St√ºtzverfahren: Kettenregel der Differentialrechnung

1. Vorw√§rtsdurchlauf (Forward Pass):
- Eingabedaten durchlaufen das Netz
- Ausgabe wird berechnet
- Fehler wird durch Vergleich mit dem Zielwert (z.‚ÄØB. √ºber MSE oder Cross-Entropy) bestimmt
2. Fehlerberechnung:
- Differenz zwischen Ausgabe und gew√ºnschtem Zielwert = Loss
3. R√ºckw√§rtsdurchlauf (Backward Pass):
- Der Fehler wird von der Ausgabeschicht zur√ºck zu den Eingabeschichten propagiert
- F√ºr jedes Gewicht wird der Gradient (Ableitung) des Fehlers berechnet
4. Gewichtsanpassung (Gradient Descent):
- Gewichte werden aktualisiert:

## ü§ñ K√ºnstliche Neuronale Netze ‚Äì Kurzfragen

### ‚ùì Wie gro√ü soll ein KNN sein?
> So gro√ü wie n√∂tig, aber so klein wie m√∂glich.  
> Zu viele Neuronen ‚Üí Overfitting  
> Zu wenige ‚Üí unzureichende Lernf√§higkeit

---

### ‚ùì Wie viele verborgene Schichten ben√∂tigt man?
> F√ºr einfache Probleme reicht **eine** Schicht.  
> Komplexere Probleme ‚Üí **mehrere Schichten (Deep Learning)**  
> Achtung: Mehr Schichten = schwieriger zu trainieren

---

### ‚ùì Kann ein trainiertes Netzwerk auf beliebige Testdaten generalisieren?
> ‚ùå Nein.  
> Nur wenn Testdaten **√§hnlich verteilt** sind wie die Trainingsdaten.  
> Sonst drohen **Overfitting** oder schlechte Vorhersageleistung.

---

### ‚ùì Kann man die Funktion \( y = F(X, W) \) eines trainierten Netzes finden?
> ‚úÖ Ja, **theoretisch m√∂glich**, durch vollst√§ndiges Einsetzen aller Gewichte und Aktivierungen.  
> ‚ùå Aber **praktisch un√ºbersichtlich** und nicht interpretierbar bei gro√üen Netzen (nicht transparent).

# ü§ñ Deep Learning ‚Äì RNN, LSTM, CNN & Convolution

## üîÅ Was ist ein RNN (Recurrent Neural Network)?

Ein **RNN** ist ein neuronales Netz, das f√ºr **sequenzielle Daten** (z.‚ÄØB. Sprache, Text, Zeitreihen) entwickelt wurde.  
Es nutzt eine **R√ºckkopplungsschleife**, sodass **Informationen aus fr√ºheren Zeitschritten** weitergegeben werden k√∂nnen.

### üîß Besonderheiten:
- Jeder Zeitschritt erh√§lt zus√§tzlich zum Input auch den **Zustand vom vorherigen Schritt**:  
  \( h_t = f(Wx_t + Uh_{t-1} + b) \)
- Ideal f√ºr: **Texte, Sprache, Musik, Zeitreihen**

### ‚ùå Problem:
- **Vanishing/Exploding Gradients** ‚Üí Schwierigkeiten beim Lernen **langer Abh√§ngigkeiten**

---

## üß† Was ist Deep Learning?

**Deep Learning** ist maschinelles Lernen mit **mehrschichtigen neuronalen Netzen** (deep = tief).

### üîß Merkmale:
- Besteht aus **vielen Hidden Layers**
- Nutzt **Backpropagation** zur Gewichtsanpassung
- F√ºhrt oft zu **automatischer Merkmalsextraktion**
- Erfolgreich bei:  
  - Bildverarbeitung  
  - Sprachverarbeitung  
  - Textklassifikation  
  - Spiel-KI

---

## ‚è≥ Was ist ein LSTM (Long Short-Term Memory)?

Ein **LSTM** ist eine **erweiterte RNN-Architektur**, die das Problem des **Vanishing Gradients** l√∂st.

### üîß Besonderheiten:
- Besteht aus **Speicherzellen**, die Informationen **√ºber viele Zeitschritte speichern** k√∂nnen
- Verwendet **drei Tore**:
  - **Input Gate** ‚Äì entscheidet, was aufgenommen wird
  - **Forget Gate** ‚Äì entscheidet, was vergessen wird
  - **Output Gate** ‚Äì entscheidet, was ausgegeben wird

‚úÖ LSTM kann **langfristige Abh√§ngigkeiten** lernen  
z.‚ÄØB. beim **√úbersetzen ganzer S√§tze**

---

## üñºÔ∏è Was ist ein CNN (Convolutional Neural Network)?

Ein **CNN** ist ein neuronales Netz, das speziell f√ºr **Bild- und Mustererkennung** entwickelt wurde.

### üîç Eigenschaften:
- Erkennt **lokale Muster** (z.‚ÄØB. Kanten, Farben) mithilfe von **Convolution-Filtern**
- Nutzt **Pooling-Schichten** zur Reduktion der Datenmenge
- Besteht typischerweise aus:
  - **Convolutional Layer**
  - **Activation Layer** (z.‚ÄØB. ReLU)
  - **Pooling Layer**
  - **Dense (fully connected) Layer**

---

## üîé Was ist eine Convolution (Faltung)?

> Eine **Convolution** ist eine mathematische Operation, bei der ein **kleiner Filter (Kernel)** √ºber das Eingabebild **gleitet** (Sliding Window).  
> Der Filter erkennt dabei **lokale Merkmale** wie Ecken oder Kanten.

### Beispiel:
Ein 3√ó3-Filter gleitet √ºber ein Bild, multipliziert mit lokalen Pixelwerten und erzeugt so eine **Feature Map**.

‚úÖ Vorteil:
- Weniger Parameter
- Gute Generalisierung
- Lokale Erkennung bei gleichzeitiger Effizienz

---
# <span style="color:red"> Bis hier!</span>
## üß© Was ist Pooling (in CNNs)?

**Pooling** ist eine Methode zur **Verkleinerung** der Feature Maps in **Convolutional Neural Networks (CNNs)**.  
Ziel: **wichtigste Informationen behalten**, aber **Gr√∂√üe und Komplexit√§t reduzieren**.

### üìâ Vorteile:
- Spart Rechenleistung
- Verhindert Overfitting
- Sorgt f√ºr **Translationstoleranz**

---

## üîù Was ist Max Pooling?

Beim **Max Pooling** wird aus jedem Pooling-Fenster (z.‚ÄØB. 2√ó2) der **gr√∂√üte Wert** ausgew√§hlt.


## üìò Klausur-Merks√§tze:

| Begriff | Erkl√§rung |
|--------|-----------|
| **RNN** | Neuronales Netz mit Ged√§chtnis f√ºr Sequenzen. Speichert vorherige Zust√§nde √ºber R√ºckkopplung. |
| **Deep Learning** | Verwendung tiefer neuronaler Netze mit mehreren Hidden Layers zur Mustererkennung. |
| **LSTM** | Erweiterung von RNN mit ‚ÄûGed√§chtnis‚Äú (Zellen + Gates) zur √úberwindung des Vanishing Gradient. |
| **CNN** | Netz f√ºr Bilderkennung, das √ºber Convolution lokale Muster erkennt und verarbeitet. |
| **Convolution** | Mathematischer Filtervorgang, bei dem Merkmale lokal aus Bildern extrahiert werden. |
| **Pooling** reduziert die Gr√∂√üe der Feature Maps und hebt wichtige Informationen hervor.|
| **Max Pooling** w√§hlt pro Bereich den gr√∂√üten Wert ‚Äì Fokus auf starke Merkmale.|


## üìö Was ist ein LLM (Large Language Model)?

Ein **LLM** ist ein gro√ües Sprachmodell, das mit **riesigen Mengen an Textdaten** trainiert wurde, um **Sprache zu verstehen und zu erzeugen**.

### üîß Merkmale:
- Basiert meist auf der **Transformer-Architektur**
- Besteht aus **Hunderten Millionen bis Milliarden von Parametern**
- Beherrscht viele Aufgaben:
  - Textgenerierung
  - Zusammenfassung
  - √úbersetzung
  - Fragebeantwortung
  - Codevervollst√§ndigung

### üß† Beispiele:
- GPT (OpenAI)
- BERT (Google)
- LLaMA (Meta)
- Claude (Anthropic)

## üìò Klausur-Merks√§tze:

- **LLMs** sind riesige Sprachmodelle, die auf Basis von Transformern trainiert wurden.


# VL 11 und 12
![alt text](image-3.png)

- Bsp.: Medizin, Technik

### unbedingte Wahrscheinlichkeit: a priori
Die unbedingte Wahrscheinlichkeit ist die ‚Äûeinfache‚Äú Wahrscheinlichkeit eines Ereignisses ‚Äì ohne dass irgendwelche weiteren Informationen bekannt sind.¬¥

### bedingte Wahrscheinlichkeit: a posteriori
Die bedingte Wahrscheinlichkeit ist die Wahrscheinlichkeit eines Ereignisses unter der Bedingung, dass ein anderes Ereignis bereits eingetreten ist.

**Der ZUsammenhang beider wird bei der Bayesschen Regel benutzt**

## Was ist ein kausales Netzwerk?
Ein kausales Netzwerk ist ein gerichteter Graph, der kausale Zusammenh√§nge zwischen Variablen modelliert.

Man kann es sich als ein Bayessches Netz vorstellen, bei dem die Kanten kausale Beziehungen und nicht nur statistische Abh√§ngigkeiten ausdr√ºcken.

### Unterschied zu einem normalen (Bayesschen) Netzwerk
Ein Bayessches Netz beschreibt bedingte Wahrscheinlichkeiten und statistische Abh√§ngigkeiten.
Ein kausales Netz geht weiter und beschreibt auch, was passiert, wenn man eingreift (interveniert).

## üîç 1. Grundlagen des probabilistischen Schlie√üens

- **Ziel**: Bewertung von Aussagen mit Wahrscheinlichkeiten, um Unsicherheiten abzubilden.
- **Herkunft der Unsicherheiten**:
  - Repr√§sentative Statistiken
  - Experteneinsch√§tzungen

### Anwendungsbereich:
- **Diagnostik**:
  - Symptome ‚Üí m√∂gliche Diagnosen
  - Unsicherheiten durch:
    - Symptomerhebung
    - Symptombewertung
    - Unzul√§nglichkeiten des Verrechnungsschemas

### Kategorien von Unsicherheit (vereinfachte Einteilung):
- sicher
- wahrscheinlich
- m√∂glich

### Verrechnungsschemata:
- Einfache, oft ad-hoc Repr√§sentationen
- Kritik: Mangelnde theoretische Fundierung

## üß† 2. Diagnostik als Klassifikationsproblem

- Zwei disjunkte Mengen:
  - **S** = Symptome
  - **D** = Diagnosen
- Gegeben: Teilmenge der Symptome
- Gesucht: Wahrscheinlichste Diagnose(n)
- M√∂glichkeit, gezielt **weitere Symptome** zur Verbesserung anzufordern

### Logik:
- **Deduktion**: Aus Diagnose folgt Symptom
- **Abduktion**: Aus beobachteten Symptomen auf Diagnose schlie√üen
- **Problematisch**: Unvollst√§ndigkeit, Widerspr√ºche

### Anforderungen an Diagnosesysteme:
- Umgang mit unvollst√§ndigem Wissen
- Plausibilit√§tspr√ºfung
- Erkennung von Mehrfachdiagnosen
- Kosteneffektive Symptomerhebung

## ‚öôÔ∏è 3. Grundalgorithmus

1. Start mit **Apriori-Wahrscheinlichkeiten** aller Diagnosen
2. Modifikation durch **Symptom-Diagnose-Wahrscheinlichkeiten**
3. Auswahl der wahrscheinlichsten Diagnose

## üìê 4. Theorem von Bayes

### Grundformel:
$$P(D_i | S) = \frac{P(D_i) \cdot P(S | D_i)}{P(S)}$$

### Beispiel:
- \( P(	ext{Bronchitis}) = 0.05 \)
- \( P(	ext{Husten}) = 0.2 \)
- \( P(	ext{Husten | Bronchitis}) = 0.8 \)
- ‚Üí \( P(	ext{Bronchitis | Husten}) = 0.2 \)

### Probleme:
- Kombinatorische Explosion bei mehreren Symptomen
- Voraussetzung: Unabh√§ngigkeit der Symptome
- Single-Fault-Annahme: nur eine Diagnose aktiv
- Statistiken m√ºssen fehlerfrei & konstant sein

### Fazit:
> Anwendung des Bayes-Theorems oft theoretisch korrekt, praktisch jedoch zu ungenau.

## üßÆ 5. Probabilistische Diagnosebewertung

### Bewertung:
- **Pro**: erwartete + beobachtete Symptome
- **Kontra**: erwartete, aber nicht beobachtete Symptome
- **Erkl√§rungswert**: nicht erwartete, aber beobachtete Symptome

### Zus√§tzliche Aspekte:
- Pr√§dispositionen
- Differentialdiagnostik

## üìä 6. Erweiterte Modelle zur Unsicherheitsverrechnung

### üî∑ Dempster-Shafer-Theorie
- Unsicherheitsintervalle statt exakter Werte: \[a, b\]
- P(Diagnose | Symptom) statt P(Symptom | Diagnose)
- Vorteile:
  - Repr√§sentation von Grobdiagnosen
  - Modellierung von Diagnosehierarchien
- Nachteil: hoher Rechenaufwand (\(2^n\) Diagnosemengen)

## üè• 7. INTERNIST-Modell (siehe ChatGPT)

- Beruht auf Expertenwissen, keine exakten Wahrscheinlichkeiten
- Bewertungsfaktoren:
  - **Evoking Strength** (0‚Äì5)
  - **Frequency** (1‚Äì5)
  - **Import Value** (0‚Äì5)
- Diagnosen in Gruppen mit √§hnlichen Merkmalen
- Bonuspunktesystem bei Mehrfachdiagnosen

## ü¶† 8. MYCIN-Modell (siehe ChatGPT)

- Ber√ºcksichtigt:
  - positive & negative Evidenz
  - Symptomkombinationen (Regeln)
- Rechnet mit:
  - **Belief** & **Disbelief**
  - Ergebnis = **Certainty Factor**

## üß™ 9. MED1-Modell

- Zweistufiges Modell:
  1. Evidenzsummierung
  2. Klassifikation in 7 Klassen (z.‚ÄØB. wahrscheinlich, gesichert)
- Vorteil: flexible Repr√§sentation
- Nachteil: komplexe Interpretation

## üîÅ 10. Alternative Ans√§tze

### üîπ Default-Logik (Reiter)
- Arbeit mit Annahmen, Revision bei neuen Infos

### üîπ Fuzzy-Logik (Zadeh)
- Wahrheitswerte ‚àà [0, 1]
- Operatoren:
  - \( F(\neg A) = 1 - F(A) \)
  - \( F(A \land B) = \min(F(A), F(B)) \)
  - \( F(A \lor B) = \max(F(A), F(B)) \)

## üßæ 11. Zusammenfassung & Fazit

- Kein Modell ist vollst√§ndig zufriedenstellend.
- Gr√∂√ütes Problem: Unsichere Datenbasis
- Kompromiss:
  - **Weniger pr√§zise, daf√ºr robuster im Umgang mit Unsicherheiten**
- Modellwahl h√§ngt ab von:
  - Einsatzgebiet
  - Verf√ºgbarkeit von Daten
  - ben√∂tigter Genauigkeit

> üîé **Empfehlung**: So viel deterministisches Schlie√üen wie m√∂glich ‚Äì so wenig probabilistisches wie n√∂tig.


# üìò KI-Vorlesung vom 13&14 ‚Äì Verst√§ndliche und Ausf√ºhrliche Zusammenfassung

## üß† Nicht-monotones Schlie√üen: Was ist das?

### Klassische Logik (monoton):
- Einmal abgeleitete Aussagen bleiben **immer** g√ºltig, selbst wenn neue Informationen dazukommen.

### Nicht-monotone Logik:
- Neue Informationen **k√∂nnen** bereits gezogene Schlussfolgerungen **ung√ºltig** machen.
- Typisches Beispiel aus dem Alltag: Man geht davon aus, dass V√∂gel fliegen k√∂nnen ‚Äì bis man einen Pinguin sieht.

### Gr√ºnde f√ºr nicht-monotones Schlie√üen:
- Erwartungen werden √ºberschrieben.
- Es tauchen Ausnahmen zu Regeln auf.
- Neue Informationen widersprechen alten Annahmen.

## üîç Ausnahmen & Negationen

- **Ausnahmen** blockieren das Ausl√∂sen einer Regel.
- **Negierte Aussagen** sagen aus, dass eine Aussage **nicht** zutrifft.
- Wichtig: In der **Closed World Assumption** (z.‚ÄØB. in PROLOG) wird "unbekannt" als "falsch" behandelt.

## üõ† Belief Revision ‚Äì Wie √§ndert man Schlussfolgerungen?

### Ziel:
- Wenn sich Informationen √§ndern, soll das System so reagieren, als h√§tte es diese Info **schon immer gehabt**.

### Methoden:
1. **Alles neu berechnen** ‚Äì funktioniert nur bei kleinen Systemen.
2. **Backtracking** ‚Äì ab dem Punkt neu berechnen, an dem sich etwas ge√§ndert hat.
3. **Minimaler Aufwand** ‚Äì nur die betroffenen Schlussfolgerungen werden korrigiert.

## üîÑ TMS ‚Äì Truth Maintenance Systems

### Typen:
- **JTMS (Justification-Based)**: Speichert direkte Begr√ºndungen.
- **ATMS (Assumption-Based)**: Speichert Basisannahmen.

### Beispiel-Regeln:
- R1: A ‚Üí B
- R2: B ‚Üí C
- R3: D ‚àß ¬¨E ‚Üí C

## üîÅ Zirkul√§re Begr√ºndungen und Schleifen

- **Problematisch**, wenn sich Schlussfolgerungen gegenseitig st√ºtzen (z.‚ÄØB. A ‚Üí B, B ‚Üí A).
- **Monotone Schleifen** sind ok ‚Äì **nicht-monotone** (mit Negationen) f√ºhren zu Endlosschleifen.

## üß© Strategien zur Schleifenbehandlung

1. **Current Support**: Nur eine Begr√ºndung z√§hlt, andere werden ignoriert ‚Äì spart Rechenaufwand.
2. **Automatische Schleifenerkennung**: 
   - z.‚ÄØB. im ITMS (Immediate-Check TMS)
   - Regeln, die zirkul√§re Evidenz liefern k√∂nnten, werden markiert und ggf. blockiert.

## üß± ATMS ‚Äì Kontextbasiertes Denken

- Jeder Schlussfolgerung ist ein **Kontext** zugeordnet = Kombination von Basisannahmen.
- **Knotenstruktur**:
  - Basisannahme
  - G√ºltigkeitskontext
  - Direkte Begr√ºndungen

## üßÆ Temporales Schlie√üen

- Aussagen k√∂nnen **zeitabh√§ngig** wahr oder falsch sein.
- Genutzt werden **modale Operatoren** wie:
  - NEXT F: ab n√§chstem Zustand
  - FUTURE F: irgendwann in der Zukunft
  - GLOBALLY F: immer

## ü©∫ Diagnostiksysteme ‚Äì √úberblick

### Wissenstypen:
- Statistisch
- Fallbasiert (√§hnliche F√§lle vergleichen)
- Heuristisch (Expertenwissen)
- Kausal (Ursache-Wirkung)

### Kontrollstrategien:
- Vorw√§rtsverkettung
- R√ºckw√§rtsverkettung
- Hypothesize-and-Test

## üíâ Beispiel: MED2-System

- Verbindet viele Diagnosestrategien:
  - Verdachtsgenerierung
  - Verdachts√ºberpr√ºfung
  - Differentialdiagnostik
  - Therapievorschl√§ge

## üîß Konstruktion ‚Äì Der Unterschied zur Diagnostik

- Ziel: **L√∂sungen aktiv konstruieren**, nicht nur ausw√§hlen.
- Beispiele:
  - Stundenplanerstellung
  - Computer-Konfiguration
  - Molekulargenetische Planung
  - Werkstoffbearbeitung

### Zwei Haupttypen:
1. **Zuordnungsprobleme**: Bestehende Objekte richtig kombinieren.
2. **Transformationsprobleme**: Zustand ver√§ndern (z.‚ÄØB. vom Rohling zum fertigen Werkst√ºck).

## üõ† Planungstechniken

- **Hierarchisches Planen**: Abstrakte Pl√§ne werden schrittweise konkretisiert.
- **Nicht-lineares Planen**: Interaktionen zwischen Teilproblemen werden ber√ºcksichtigt.
- **Differenzenmethode**: Differenz zwischen Ist- und Sollzustand bestimmen ‚Üí passenden Plan generieren.
- **Wissensbasiertes Planen**: Verwendung von vorgefertigten Planskeletten.

## üíª Beispiel: R1-System

- Konfiguration von DEC-Computern.
- Arbeitet in **6 Phasen** mit einfachen Regeln.
- Probleme:
  - Komplexe Wartung (30 Personen n√∂tig!)
  - Geringe Transparenz der Wissensbasis

---

# ‚úÖ Fazit

- **Nicht-monotones Schlie√üen** spiegelt die Realit√§t besser wider als klassische Logik.
- **Belief Revision Systeme** wie JTMS & ATMS erm√∂glichen flexible und nachvollziehbare Reaktion auf neue Informationen.
- **Diagnostik** und **Konstruktion** sind zwei zentrale Anwendungen der KI.
- Gute Planung erfordert **Abstraktion**, **Wissensrepr√§sentation** und oft **heuristische Regeln**.

